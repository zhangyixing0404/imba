{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "print('Loading data ...')\n",
    "path = 'C:\\\\Kaggle\\\\Zillow\\\\input\\\\'\n",
    "\n",
    "train = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\train_2016.csv')\n",
    "properties = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\properties_2016.csv')\n",
    "\n",
    "for c in properties.columns:\n",
    "    properties[c]=properties[c].fillna(-1)\n",
    "    if properties[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(properties[c].values))\n",
    "        properties[c] = lbl.transform(list(properties[c].values))\n",
    "df_train = train.merge(properties, how='left', on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#life of property\n",
    "def prepare_additional_feature(df_train):\n",
    "    df_train['N-life'] = 2018 - df_train['yearbuilt']\n",
    "\n",
    "    #error in calculation of the finished living area of home\n",
    "    df_train['N-LivingAreaError'] = df_train['calculatedfinishedsquarefeet']/df_train['finishedsquarefeet12']\n",
    "\n",
    "    #proportion of living area\n",
    "    df_train['N-LivingAreaProp'] = df_train['calculatedfinishedsquarefeet']/df_train['lotsizesquarefeet']\n",
    "    df_train['N-LivingAreaProp2'] = df_train['finishedsquarefeet12']/df_train['finishedsquarefeet15']\n",
    "\n",
    "    #Amout of extra space\n",
    "    df_train['N-ExtraSpace'] = df_train['lotsizesquarefeet'] - df_train['calculatedfinishedsquarefeet'] \n",
    "    df_train['N-ExtraSpace-2'] = df_train['finishedsquarefeet15'] - df_train['finishedsquarefeet12'] \n",
    "\n",
    "    #Total number of rooms\n",
    "    df_train['N-TotalRooms'] = df_train['bathroomcnt']*df_train['bedroomcnt']\n",
    "\n",
    "    #Average room size\n",
    "    df_train['N-AvRoomSize'] = df_train['calculatedfinishedsquarefeet']/df_train['roomcnt'] \n",
    "\n",
    "    # Number of Extra rooms\n",
    "    df_train['N-ExtraRooms'] = df_train['roomcnt'] - df_train['N-TotalRooms'] \n",
    "\n",
    "    #Ratio of the built structure value to land area\n",
    "    df_train['N-ValueProp'] = df_train['structuretaxvaluedollarcnt']/df_train['landtaxvaluedollarcnt']\n",
    "\n",
    "    #Does property have a garage, pool or hot tub and AC?\n",
    "    df_train['N-GarPoolAC'] = ((df_train['garagecarcnt']>0) & (df_train['pooltypeid10']>0) & (df_train['airconditioningtypeid']!=5))*1 \n",
    "\n",
    "    df_train[\"N-location\"] = df_train[\"latitude\"] + df_train[\"longitude\"]\n",
    "    df_train[\"N-location-2\"] = df_train[\"latitude\"]*df_train[\"longitude\"]\n",
    "    df_train[\"N-location-2round\"] = df_train[\"N-location-2\"].round(-4)\n",
    "\n",
    "    df_train[\"N-latitude-round\"] = df_train[\"latitude\"].round(-4)\n",
    "    df_train[\"N-longitude-round\"] = df_train[\"longitude\"].round(-4)\n",
    "    \n",
    "    #Ratio of tax of property over parcel\n",
    "    df_train['N-ValueRatio'] = df_train['taxvaluedollarcnt']/df_train['taxamount']\n",
    "\n",
    "    #TotalTaxScore\n",
    "    df_train['N-TaxScore'] = df_train['taxvaluedollarcnt']*df_train['taxamount']\n",
    "\n",
    "    #polnomials of tax delinquency year\n",
    "    df_train[\"N-taxdelinquencyyear-2\"] = df_train[\"taxdelinquencyyear\"] ** 2\n",
    "    df_train[\"N-taxdelinquencyyear-3\"] = df_train[\"taxdelinquencyyear\"] ** 3\n",
    "\n",
    "    #Length of time since unpaid taxes\n",
    "    df_train['N-life'] = 2018 - df_train['taxdelinquencyyear']\n",
    "    \n",
    "    #Number of properties in the zip\n",
    "    zip_count = df_train['regionidzip'].value_counts().to_dict()\n",
    "    df_train['N-zip_count'] = df_train['regionidzip'].map(zip_count)\n",
    "\n",
    "    #Number of properties in the city\n",
    "    city_count = df_train['regionidcity'].value_counts().to_dict()\n",
    "    df_train['N-city_count'] = df_train['regionidcity'].map(city_count)\n",
    "\n",
    "    #Number of properties in the city\n",
    "    region_count = df_train['regionidcounty'].value_counts().to_dict()\n",
    "    df_train['N-county_count'] = df_train['regionidcounty'].map(city_count)\n",
    "    \n",
    "        #Indicator whether it has AC or not\n",
    "    df_train['N-ACInd'] = (df_train['airconditioningtypeid']!=5)*1\n",
    "\n",
    "    #Indicator whether it has Heating or not \n",
    "    df_train['N-HeatInd'] = (df_train['heatingorsystemtypeid']!=13)*1\n",
    "\n",
    "    #There's 25 different property uses - let's compress them down to 4 categories\n",
    "    df_train['N-PropType'] = df_train.propertylandusetypeid.replace({31 : \"Mixed\", \n",
    "                                                                     46 : \"Other\", 47 : \"Mixed\", 246 : \"Mixed\", \n",
    "                                                                     247 : \"Mixed\", 248 : \"Mixed\", 260 : \"Home\", \n",
    "                                                                     261 : \"Home\", 262 : \"Home\", 263 : \"Home\", \n",
    "                                                                     264 : \"Home\", 265 : \"Home\", 266 : \"Home\", \n",
    "                                                                     267 : \"Home\", 268 : \"Home\", 269 : \"Not Built\", \n",
    "                                                                     270 : \"Home\", 271 : \"Home\", 273 : \"Home\", \n",
    "                                                                     274 : \"Other\", 275 : \"Home\", 276 : \"Home\", \n",
    "                                                                     279 : \"Home\", 290 : \"Not Built\", \n",
    "                                                                     291 : \"Not Built\" })\n",
    "    \n",
    "    #polnomials of the variable\n",
    "    df_train[\"N-structuretaxvaluedollarcnt-2\"] = df_train[\"structuretaxvaluedollarcnt\"] ** 2\n",
    "    df_train[\"N-structuretaxvaluedollarcnt-3\"] = df_train[\"structuretaxvaluedollarcnt\"] ** 3\n",
    "\n",
    "    #Average structuretaxvaluedollarcnt by city\n",
    "    group = df_train.groupby('regionidcity')['structuretaxvaluedollarcnt'].aggregate('mean').to_dict()\n",
    "    df_train['N-Avg-structuretaxvaluedollarcnt'] = df_train['regionidcity'].map(group)\n",
    "\n",
    "    #Deviation away from average\n",
    "    df_train['N-Dev-structuretaxvaluedollarcnt'] = abs((df_train['structuretaxvaluedollarcnt'] - \n",
    "                                                        df_train['N-Avg-structuretaxvaluedollarcnt']))/df_train['N-Avg-structuretaxvaluedollarcnt']\n",
    "    \n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = prepare_additional_feature(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['airconditioningtypeid', 'bathroomcnt', 'bedroomcnt',\n",
    "           'buildingqualitytypeid', 'calculatedbathnbr',\n",
    "           'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet',\n",
    "           'finishedsquarefeet12', 'finishedsquarefeet15',\n",
    "           'finishedsquarefeet50', 'fips', 'fullbathcnt', 'garagetotalsqft',\n",
    "           'hashottuborspa', 'heatingorsystemtypeid', 'latitude',\n",
    "           'lotsizesquarefeet', 'poolcnt', 'pooltypeid7',\n",
    "           'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity',\n",
    "           'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt',\n",
    "           'unitcnt', 'yearbuilt', 'numberofstories',\n",
    "           'structuretaxvaluedollarcnt', 'taxvaluedollarcnt',\n",
    "           'landtaxvaluedollarcnt', 'taxamount', 'taxdelinquencyyear',\n",
    "           'censustractandblock', 'N-LivingAreaProp', 'N-LivingAreaProp2',\n",
    "           'N-ExtraSpace', 'N-ExtraSpace-2', 'N-TotalRooms', 'N-AvRoomSize',\n",
    "           'N-ExtraRooms', 'N-ValueProp', 'N-latitude-round', 'N-ValueRatio',\n",
    "           'N-TaxScore', 'N-taxdelinquencyyear-2', 'N-zip_count',\n",
    "           'N-city_count', 'N-structuretaxvaluedollarcnt-2',\n",
    "           'N-structuretaxvaluedollarcnt-3',\n",
    "           'N-Avg-structuretaxvaluedollarcnt',\n",
    "           'N-Dev-structuretaxvaluedollarcnt']\n",
    "\n",
    "categorical_f = ['airconditioningtypeid', 'architecturalstyletypeid', 'buildingclasstypeid', 'heatingorsystemtypeid',\n",
    "                 'propertycountylandusecode', 'propertylandusetypeid', 'storytypeid', 'typeconstructiontypeid', \n",
    "                 'regionidcounty', 'regionidcity','regionidzip','regionidneighborhood'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90275, 53) (90275,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df_train = df_train[features]\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], \n",
    "                        axis=1, errors = 'ignore')\n",
    "y_train = df_train['logerror'].values\n",
    "x_train = x_train[features]\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "del df_train; gc.collect()\n",
    "\n",
    "#split = 80000\n",
    "#index = np.arange(y_train.shape[0])\n",
    "#np.random.shuffle(index)\n",
    "#x_train = x_train.loc[index]\n",
    "#y_train = y_train[index]\n",
    "#y_train[y_train>0]=1\n",
    "#y_train[y_train<=0]=0\n",
    "#x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "#x_train = x_train.values.astype(np.float32, copy=False)\n",
    "#x_valid = x_valid.values.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2fcbcffc2b84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0my_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_bar\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mvalid_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhang\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\svm\\classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[1;32m--> 375\u001b[1;33m                          dtype=np.float64, order=\"C\")\n\u001b[0m\u001b[0;32m    376\u001b[0m         \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l2'\u001b[0m  \u001b[1;31m# SVR only accepts l2 penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "\u001b[1;32mC:\\Users\\yzhang\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Users\\yzhang\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yzhang\\AppData\\Roaming\\Python\\Python35\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 58\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'mae'},\n",
    "    'num_leaves': 96,\n",
    "    'min_sum_hessian_in_leaf':20,\n",
    "    'min_hessian':10,\n",
    "    'min_data':500,\n",
    "    'max_depth': -12,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "    \n",
    "kf = KFold(n_splits=10)\n",
    "average_loss = 0\n",
    "for train_index, valid_index in kf.split(x_train):\n",
    "    train_data, valid_data = x_train.loc[train_index], x_train.loc[valid_index]\n",
    "    train_label, valid_label = y_train[train_index], y_train[valid_index]\n",
    "    \n",
    "    model = LinearSVR()\n",
    "    model.fit(train_data.fillna(0), train_label)\n",
    "    y_bar = model.predict(valid_data.fillna(0))\n",
    "    loss = np.mean(np.abs(y_bar-valid_label)) \n",
    "    print(loss)\n",
    "    average_loss += loss\n",
    "average_loss/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0748197\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0747816\n",
      "[3]\tvalid_0's l1: 0.0747415\n",
      "[4]\tvalid_0's l1: 0.0747045\n",
      "[5]\tvalid_0's l1: 0.0746687\n",
      "[6]\tvalid_0's l1: 0.0746406\n",
      "[7]\tvalid_0's l1: 0.0746228\n",
      "[8]\tvalid_0's l1: 0.0745933\n",
      "[9]\tvalid_0's l1: 0.0745631\n",
      "[10]\tvalid_0's l1: 0.0745412\n",
      "[11]\tvalid_0's l1: 0.0745115\n",
      "[12]\tvalid_0's l1: 0.0744879\n",
      "[13]\tvalid_0's l1: 0.0744648\n",
      "[14]\tvalid_0's l1: 0.0744438\n",
      "[15]\tvalid_0's l1: 0.0744216\n",
      "[16]\tvalid_0's l1: 0.0744037\n",
      "[17]\tvalid_0's l1: 0.0743919\n",
      "[18]\tvalid_0's l1: 0.0743727\n",
      "[19]\tvalid_0's l1: 0.0743599\n",
      "[20]\tvalid_0's l1: 0.0743473\n",
      "[21]\tvalid_0's l1: 0.0743353\n",
      "[22]\tvalid_0's l1: 0.0743219\n",
      "[23]\tvalid_0's l1: 0.0743109\n",
      "[24]\tvalid_0's l1: 0.074301\n",
      "[25]\tvalid_0's l1: 0.0742911\n",
      "[26]\tvalid_0's l1: 0.0742835\n",
      "[27]\tvalid_0's l1: 0.0742785\n",
      "[28]\tvalid_0's l1: 0.0742719\n",
      "[29]\tvalid_0's l1: 0.0742653\n",
      "[30]\tvalid_0's l1: 0.0742676\n",
      "[31]\tvalid_0's l1: 0.0742597\n",
      "[32]\tvalid_0's l1: 0.0742547\n",
      "[33]\tvalid_0's l1: 0.0742447\n",
      "[34]\tvalid_0's l1: 0.0742388\n",
      "[35]\tvalid_0's l1: 0.0742321\n",
      "[36]\tvalid_0's l1: 0.0742174\n",
      "[37]\tvalid_0's l1: 0.0742034\n",
      "[38]\tvalid_0's l1: 0.0742015\n",
      "[39]\tvalid_0's l1: 0.074191\n",
      "[40]\tvalid_0's l1: 0.0741825\n",
      "[41]\tvalid_0's l1: 0.0741785\n",
      "[42]\tvalid_0's l1: 0.0741753\n",
      "[43]\tvalid_0's l1: 0.0741742\n",
      "[44]\tvalid_0's l1: 0.0741677\n",
      "[45]\tvalid_0's l1: 0.0741732\n",
      "[46]\tvalid_0's l1: 0.0741714\n",
      "[47]\tvalid_0's l1: 0.0741653\n",
      "[48]\tvalid_0's l1: 0.0741673\n",
      "[49]\tvalid_0's l1: 0.0741706\n",
      "[50]\tvalid_0's l1: 0.0741685\n",
      "[51]\tvalid_0's l1: 0.0741715\n",
      "[52]\tvalid_0's l1: 0.0741749\n",
      "[53]\tvalid_0's l1: 0.0741729\n",
      "[54]\tvalid_0's l1: 0.0741645\n",
      "[55]\tvalid_0's l1: 0.074167\n",
      "[56]\tvalid_0's l1: 0.0741604\n",
      "[57]\tvalid_0's l1: 0.0741593\n",
      "[58]\tvalid_0's l1: 0.0741564\n",
      "[59]\tvalid_0's l1: 0.0741514\n",
      "[60]\tvalid_0's l1: 0.0741525\n",
      "[61]\tvalid_0's l1: 0.0741527\n",
      "[62]\tvalid_0's l1: 0.0741537\n",
      "[63]\tvalid_0's l1: 0.0741487\n",
      "[64]\tvalid_0's l1: 0.07415\n",
      "[65]\tvalid_0's l1: 0.0741494\n",
      "[66]\tvalid_0's l1: 0.0741501\n",
      "[67]\tvalid_0's l1: 0.0741542\n",
      "[68]\tvalid_0's l1: 0.0741567\n",
      "[69]\tvalid_0's l1: 0.0741599\n",
      "[70]\tvalid_0's l1: 0.0741697\n",
      "[71]\tvalid_0's l1: 0.0741678\n",
      "[72]\tvalid_0's l1: 0.0741716\n",
      "[73]\tvalid_0's l1: 0.0741735\n",
      "[74]\tvalid_0's l1: 0.0741694\n",
      "[75]\tvalid_0's l1: 0.0741687\n",
      "[76]\tvalid_0's l1: 0.074171\n",
      "[77]\tvalid_0's l1: 0.0741759\n",
      "[78]\tvalid_0's l1: 0.0741775\n",
      "[79]\tvalid_0's l1: 0.0741767\n",
      "[80]\tvalid_0's l1: 0.0741815\n",
      "[81]\tvalid_0's l1: 0.0741807\n",
      "[82]\tvalid_0's l1: 0.0741804\n",
      "[83]\tvalid_0's l1: 0.0741894\n",
      "[84]\tvalid_0's l1: 0.0741864\n",
      "[85]\tvalid_0's l1: 0.0741861\n",
      "[86]\tvalid_0's l1: 0.0741854\n",
      "[87]\tvalid_0's l1: 0.074179\n",
      "[88]\tvalid_0's l1: 0.0741793\n",
      "[89]\tvalid_0's l1: 0.0741704\n",
      "[90]\tvalid_0's l1: 0.0741703\n",
      "[91]\tvalid_0's l1: 0.0741756\n",
      "[92]\tvalid_0's l1: 0.0741743\n",
      "[93]\tvalid_0's l1: 0.0741736\n",
      "[94]\tvalid_0's l1: 0.0741705\n",
      "[95]\tvalid_0's l1: 0.0741707\n",
      "[96]\tvalid_0's l1: 0.0741729\n",
      "[97]\tvalid_0's l1: 0.0741646\n",
      "[98]\tvalid_0's l1: 0.0741642\n",
      "[99]\tvalid_0's l1: 0.0741699\n",
      "[100]\tvalid_0's l1: 0.0741717\n",
      "[101]\tvalid_0's l1: 0.0741737\n",
      "[102]\tvalid_0's l1: 0.0741712\n",
      "[103]\tvalid_0's l1: 0.0741721\n",
      "[104]\tvalid_0's l1: 0.0741723\n",
      "[105]\tvalid_0's l1: 0.0741718\n",
      "[106]\tvalid_0's l1: 0.0741704\n",
      "[107]\tvalid_0's l1: 0.0741715\n",
      "[108]\tvalid_0's l1: 0.0741685\n",
      "[109]\tvalid_0's l1: 0.0741674\n",
      "[110]\tvalid_0's l1: 0.0741685\n",
      "[111]\tvalid_0's l1: 0.0741689\n",
      "[112]\tvalid_0's l1: 0.0741721\n",
      "[113]\tvalid_0's l1: 0.0741747\n",
      "[114]\tvalid_0's l1: 0.0741733\n",
      "[115]\tvalid_0's l1: 0.0741753\n",
      "[116]\tvalid_0's l1: 0.0741743\n",
      "[117]\tvalid_0's l1: 0.0741743\n",
      "[118]\tvalid_0's l1: 0.0741726\n",
      "[119]\tvalid_0's l1: 0.0741714\n",
      "[120]\tvalid_0's l1: 0.0741781\n",
      "[121]\tvalid_0's l1: 0.0741762\n",
      "[122]\tvalid_0's l1: 0.0741755\n",
      "[123]\tvalid_0's l1: 0.07418\n",
      "[124]\tvalid_0's l1: 0.0741806\n",
      "[125]\tvalid_0's l1: 0.0741815\n",
      "[126]\tvalid_0's l1: 0.0741831\n",
      "[127]\tvalid_0's l1: 0.0741782\n",
      "[128]\tvalid_0's l1: 0.0741841\n",
      "[129]\tvalid_0's l1: 0.0741871\n",
      "[130]\tvalid_0's l1: 0.0741927\n",
      "[131]\tvalid_0's l1: 0.074194\n",
      "[132]\tvalid_0's l1: 0.0741921\n",
      "[133]\tvalid_0's l1: 0.0741866\n",
      "[134]\tvalid_0's l1: 0.074182\n",
      "[135]\tvalid_0's l1: 0.074184\n",
      "[136]\tvalid_0's l1: 0.0741844\n",
      "[137]\tvalid_0's l1: 0.0741886\n",
      "[138]\tvalid_0's l1: 0.0741892\n",
      "[139]\tvalid_0's l1: 0.0741905\n",
      "[140]\tvalid_0's l1: 0.0741868\n",
      "[141]\tvalid_0's l1: 0.0741859\n",
      "[142]\tvalid_0's l1: 0.0741879\n",
      "[143]\tvalid_0's l1: 0.0741913\n",
      "[144]\tvalid_0's l1: 0.0741992\n",
      "[145]\tvalid_0's l1: 0.074202\n",
      "[146]\tvalid_0's l1: 0.0742071\n",
      "[147]\tvalid_0's l1: 0.0742074\n",
      "[148]\tvalid_0's l1: 0.074209\n",
      "[149]\tvalid_0's l1: 0.0742102\n",
      "[150]\tvalid_0's l1: 0.0742155\n",
      "[151]\tvalid_0's l1: 0.0742201\n",
      "[152]\tvalid_0's l1: 0.0742178\n",
      "[153]\tvalid_0's l1: 0.0742176\n",
      "[154]\tvalid_0's l1: 0.0742221\n",
      "[155]\tvalid_0's l1: 0.0742222\n",
      "[156]\tvalid_0's l1: 0.074226\n",
      "[157]\tvalid_0's l1: 0.0742245\n",
      "[158]\tvalid_0's l1: 0.0742289\n",
      "[159]\tvalid_0's l1: 0.0742309\n",
      "[160]\tvalid_0's l1: 0.0742326\n",
      "[161]\tvalid_0's l1: 0.0742331\n",
      "[162]\tvalid_0's l1: 0.074236\n",
      "[163]\tvalid_0's l1: 0.0742384\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 0.0741487\n",
      "[1]\tvalid_0's l1: 0.0727345\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0726963\n",
      "[3]\tvalid_0's l1: 0.0726554\n",
      "[4]\tvalid_0's l1: 0.0726155\n",
      "[5]\tvalid_0's l1: 0.0725801\n",
      "[6]\tvalid_0's l1: 0.0725544\n",
      "[7]\tvalid_0's l1: 0.0725386\n",
      "[8]\tvalid_0's l1: 0.0725066\n",
      "[9]\tvalid_0's l1: 0.072482\n",
      "[10]\tvalid_0's l1: 0.0724714\n",
      "[11]\tvalid_0's l1: 0.0724451\n",
      "[12]\tvalid_0's l1: 0.0724282\n",
      "[13]\tvalid_0's l1: 0.072412\n",
      "[14]\tvalid_0's l1: 0.0723952\n",
      "[15]\tvalid_0's l1: 0.0723756\n",
      "[16]\tvalid_0's l1: 0.0723571\n",
      "[17]\tvalid_0's l1: 0.0723447\n",
      "[18]\tvalid_0's l1: 0.0723326\n",
      "[19]\tvalid_0's l1: 0.0723129\n",
      "[20]\tvalid_0's l1: 0.072298\n",
      "[21]\tvalid_0's l1: 0.0722871\n",
      "[22]\tvalid_0's l1: 0.0722746\n",
      "[23]\tvalid_0's l1: 0.072259\n",
      "[24]\tvalid_0's l1: 0.0722513\n",
      "[25]\tvalid_0's l1: 0.0722404\n",
      "[26]\tvalid_0's l1: 0.0722288\n",
      "[27]\tvalid_0's l1: 0.0722193\n",
      "[28]\tvalid_0's l1: 0.0722139\n",
      "[29]\tvalid_0's l1: 0.0722103\n",
      "[30]\tvalid_0's l1: 0.0722107\n",
      "[31]\tvalid_0's l1: 0.0722003\n",
      "[32]\tvalid_0's l1: 0.0721876\n",
      "[33]\tvalid_0's l1: 0.0721788\n",
      "[34]\tvalid_0's l1: 0.0721697\n",
      "[35]\tvalid_0's l1: 0.0721698\n",
      "[36]\tvalid_0's l1: 0.0721659\n",
      "[37]\tvalid_0's l1: 0.072163\n",
      "[38]\tvalid_0's l1: 0.0721604\n",
      "[39]\tvalid_0's l1: 0.0721582\n",
      "[40]\tvalid_0's l1: 0.0721557\n",
      "[41]\tvalid_0's l1: 0.0721539\n",
      "[42]\tvalid_0's l1: 0.0721479\n",
      "[43]\tvalid_0's l1: 0.0721414\n",
      "[44]\tvalid_0's l1: 0.0721424\n",
      "[45]\tvalid_0's l1: 0.0721391\n",
      "[46]\tvalid_0's l1: 0.0721391\n",
      "[47]\tvalid_0's l1: 0.0721366\n",
      "[48]\tvalid_0's l1: 0.0721385\n",
      "[49]\tvalid_0's l1: 0.0721346\n",
      "[50]\tvalid_0's l1: 0.0721285\n",
      "[51]\tvalid_0's l1: 0.0721254\n",
      "[52]\tvalid_0's l1: 0.0721224\n",
      "[53]\tvalid_0's l1: 0.0721165\n",
      "[54]\tvalid_0's l1: 0.0721139\n",
      "[55]\tvalid_0's l1: 0.0721104\n",
      "[56]\tvalid_0's l1: 0.0721124\n",
      "[57]\tvalid_0's l1: 0.0721128\n",
      "[58]\tvalid_0's l1: 0.0721108\n",
      "[59]\tvalid_0's l1: 0.0721066\n",
      "[60]\tvalid_0's l1: 0.0721034\n",
      "[61]\tvalid_0's l1: 0.0721\n",
      "[62]\tvalid_0's l1: 0.0720988\n",
      "[63]\tvalid_0's l1: 0.0720969\n",
      "[64]\tvalid_0's l1: 0.0720934\n",
      "[65]\tvalid_0's l1: 0.072096\n",
      "[66]\tvalid_0's l1: 0.0720998\n",
      "[67]\tvalid_0's l1: 0.0721011\n",
      "[68]\tvalid_0's l1: 0.0721031\n",
      "[69]\tvalid_0's l1: 0.0721065\n",
      "[70]\tvalid_0's l1: 0.0721077\n",
      "[71]\tvalid_0's l1: 0.0721069\n",
      "[72]\tvalid_0's l1: 0.072106\n",
      "[73]\tvalid_0's l1: 0.072108\n",
      "[74]\tvalid_0's l1: 0.0721051\n",
      "[75]\tvalid_0's l1: 0.0721069\n",
      "[76]\tvalid_0's l1: 0.0721045\n",
      "[77]\tvalid_0's l1: 0.0721025\n",
      "[78]\tvalid_0's l1: 0.0721012\n",
      "[79]\tvalid_0's l1: 0.072102\n",
      "[80]\tvalid_0's l1: 0.0720993\n",
      "[81]\tvalid_0's l1: 0.072099\n",
      "[82]\tvalid_0's l1: 0.0720973\n",
      "[83]\tvalid_0's l1: 0.0720981\n",
      "[84]\tvalid_0's l1: 0.0721014\n",
      "[85]\tvalid_0's l1: 0.0720998\n",
      "[86]\tvalid_0's l1: 0.0720945\n",
      "[87]\tvalid_0's l1: 0.0720993\n",
      "[88]\tvalid_0's l1: 0.0720997\n",
      "[89]\tvalid_0's l1: 0.0721\n",
      "[90]\tvalid_0's l1: 0.0720998\n",
      "[91]\tvalid_0's l1: 0.0721007\n",
      "[92]\tvalid_0's l1: 0.0720986\n",
      "[93]\tvalid_0's l1: 0.0720965\n",
      "[94]\tvalid_0's l1: 0.0720969\n",
      "[95]\tvalid_0's l1: 0.0720986\n",
      "[96]\tvalid_0's l1: 0.0720988\n",
      "[97]\tvalid_0's l1: 0.0720983\n",
      "[98]\tvalid_0's l1: 0.0721015\n",
      "[99]\tvalid_0's l1: 0.0721001\n",
      "[100]\tvalid_0's l1: 0.0721015\n",
      "[101]\tvalid_0's l1: 0.0721008\n",
      "[102]\tvalid_0's l1: 0.0721051\n",
      "[103]\tvalid_0's l1: 0.0721046\n",
      "[104]\tvalid_0's l1: 0.0721028\n",
      "[105]\tvalid_0's l1: 0.072103\n",
      "[106]\tvalid_0's l1: 0.0721051\n",
      "[107]\tvalid_0's l1: 0.0721069\n",
      "[108]\tvalid_0's l1: 0.0721113\n",
      "[109]\tvalid_0's l1: 0.0721114\n",
      "[110]\tvalid_0's l1: 0.0721134\n",
      "[111]\tvalid_0's l1: 0.0721136\n",
      "[112]\tvalid_0's l1: 0.0721134\n",
      "[113]\tvalid_0's l1: 0.0721115\n",
      "[114]\tvalid_0's l1: 0.0721165\n",
      "[115]\tvalid_0's l1: 0.0721206\n",
      "[116]\tvalid_0's l1: 0.0721205\n",
      "[117]\tvalid_0's l1: 0.0721255\n",
      "[118]\tvalid_0's l1: 0.0721266\n",
      "[119]\tvalid_0's l1: 0.0721257\n",
      "[120]\tvalid_0's l1: 0.0721267\n",
      "[121]\tvalid_0's l1: 0.0721226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122]\tvalid_0's l1: 0.0721167\n",
      "[123]\tvalid_0's l1: 0.0721219\n",
      "[124]\tvalid_0's l1: 0.0721184\n",
      "[125]\tvalid_0's l1: 0.0721208\n",
      "[126]\tvalid_0's l1: 0.0721213\n",
      "[127]\tvalid_0's l1: 0.0721237\n",
      "[128]\tvalid_0's l1: 0.0721277\n",
      "[129]\tvalid_0's l1: 0.0721223\n",
      "[130]\tvalid_0's l1: 0.0721218\n",
      "[131]\tvalid_0's l1: 0.0721236\n",
      "[132]\tvalid_0's l1: 0.0721272\n",
      "[133]\tvalid_0's l1: 0.0721283\n",
      "[134]\tvalid_0's l1: 0.0721308\n",
      "[135]\tvalid_0's l1: 0.0721322\n",
      "[136]\tvalid_0's l1: 0.0721325\n",
      "[137]\tvalid_0's l1: 0.0721344\n",
      "[138]\tvalid_0's l1: 0.0721332\n",
      "[139]\tvalid_0's l1: 0.0721339\n",
      "[140]\tvalid_0's l1: 0.0721369\n",
      "[141]\tvalid_0's l1: 0.0721423\n",
      "[142]\tvalid_0's l1: 0.0721445\n",
      "[143]\tvalid_0's l1: 0.0721442\n",
      "[144]\tvalid_0's l1: 0.0721483\n",
      "[145]\tvalid_0's l1: 0.0721514\n",
      "[146]\tvalid_0's l1: 0.0721554\n",
      "[147]\tvalid_0's l1: 0.0721508\n",
      "[148]\tvalid_0's l1: 0.0721514\n",
      "[149]\tvalid_0's l1: 0.0721519\n",
      "[150]\tvalid_0's l1: 0.0721514\n",
      "[151]\tvalid_0's l1: 0.0721498\n",
      "[152]\tvalid_0's l1: 0.0721502\n",
      "[153]\tvalid_0's l1: 0.072148\n",
      "[154]\tvalid_0's l1: 0.072144\n",
      "[155]\tvalid_0's l1: 0.072149\n",
      "[156]\tvalid_0's l1: 0.0721475\n",
      "[157]\tvalid_0's l1: 0.0721451\n",
      "[158]\tvalid_0's l1: 0.072146\n",
      "[159]\tvalid_0's l1: 0.0721437\n",
      "[160]\tvalid_0's l1: 0.0721429\n",
      "[161]\tvalid_0's l1: 0.0721425\n",
      "[162]\tvalid_0's l1: 0.0721444\n",
      "[163]\tvalid_0's l1: 0.072144\n",
      "[164]\tvalid_0's l1: 0.0721468\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l1: 0.0720934\n",
      "[1]\tvalid_0's l1: 0.0711482\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0711043\n",
      "[3]\tvalid_0's l1: 0.0710555\n",
      "[4]\tvalid_0's l1: 0.0710141\n",
      "[5]\tvalid_0's l1: 0.0709773\n",
      "[6]\tvalid_0's l1: 0.0709405\n",
      "[7]\tvalid_0's l1: 0.0709231\n",
      "[8]\tvalid_0's l1: 0.0708948\n",
      "[9]\tvalid_0's l1: 0.070866\n",
      "[10]\tvalid_0's l1: 0.0708501\n",
      "[11]\tvalid_0's l1: 0.0708234\n",
      "[12]\tvalid_0's l1: 0.0707963\n",
      "[13]\tvalid_0's l1: 0.07078\n",
      "[14]\tvalid_0's l1: 0.0707561\n",
      "[15]\tvalid_0's l1: 0.0707325\n",
      "[16]\tvalid_0's l1: 0.0707172\n",
      "[17]\tvalid_0's l1: 0.0707042\n",
      "[18]\tvalid_0's l1: 0.0706897\n",
      "[19]\tvalid_0's l1: 0.0706766\n",
      "[20]\tvalid_0's l1: 0.0706576\n",
      "[21]\tvalid_0's l1: 0.0706348\n",
      "[22]\tvalid_0's l1: 0.0706149\n",
      "[23]\tvalid_0's l1: 0.0705999\n",
      "[24]\tvalid_0's l1: 0.0705839\n",
      "[25]\tvalid_0's l1: 0.0705688\n",
      "[26]\tvalid_0's l1: 0.0705541\n",
      "[27]\tvalid_0's l1: 0.0705417\n",
      "[28]\tvalid_0's l1: 0.070538\n",
      "[29]\tvalid_0's l1: 0.0705253\n",
      "[30]\tvalid_0's l1: 0.0705178\n",
      "[31]\tvalid_0's l1: 0.0705095\n",
      "[32]\tvalid_0's l1: 0.0705027\n",
      "[33]\tvalid_0's l1: 0.0704873\n",
      "[34]\tvalid_0's l1: 0.0704753\n",
      "[35]\tvalid_0's l1: 0.0704648\n",
      "[36]\tvalid_0's l1: 0.0704565\n",
      "[37]\tvalid_0's l1: 0.070448\n",
      "[38]\tvalid_0's l1: 0.0704357\n",
      "[39]\tvalid_0's l1: 0.0704278\n",
      "[40]\tvalid_0's l1: 0.0704219\n",
      "[41]\tvalid_0's l1: 0.0704183\n",
      "[42]\tvalid_0's l1: 0.070407\n",
      "[43]\tvalid_0's l1: 0.0703996\n",
      "[44]\tvalid_0's l1: 0.0703883\n",
      "[45]\tvalid_0's l1: 0.0703852\n",
      "[46]\tvalid_0's l1: 0.0703757\n",
      "[47]\tvalid_0's l1: 0.0703753\n",
      "[48]\tvalid_0's l1: 0.07037\n",
      "[49]\tvalid_0's l1: 0.0703647\n",
      "[50]\tvalid_0's l1: 0.0703596\n",
      "[51]\tvalid_0's l1: 0.0703605\n",
      "[52]\tvalid_0's l1: 0.0703547\n",
      "[53]\tvalid_0's l1: 0.0703551\n",
      "[54]\tvalid_0's l1: 0.0703538\n",
      "[55]\tvalid_0's l1: 0.0703544\n",
      "[56]\tvalid_0's l1: 0.0703512\n",
      "[57]\tvalid_0's l1: 0.0703424\n",
      "[58]\tvalid_0's l1: 0.0703375\n",
      "[59]\tvalid_0's l1: 0.0703304\n",
      "[60]\tvalid_0's l1: 0.0703273\n",
      "[61]\tvalid_0's l1: 0.0703254\n",
      "[62]\tvalid_0's l1: 0.0703223\n",
      "[63]\tvalid_0's l1: 0.070319\n",
      "[64]\tvalid_0's l1: 0.0703139\n",
      "[65]\tvalid_0's l1: 0.0703127\n",
      "[66]\tvalid_0's l1: 0.0703146\n",
      "[67]\tvalid_0's l1: 0.0703116\n",
      "[68]\tvalid_0's l1: 0.0703116\n",
      "[69]\tvalid_0's l1: 0.0703058\n",
      "[70]\tvalid_0's l1: 0.0703022\n",
      "[71]\tvalid_0's l1: 0.0703006\n",
      "[72]\tvalid_0's l1: 0.0702976\n",
      "[73]\tvalid_0's l1: 0.0702965\n",
      "[74]\tvalid_0's l1: 0.0702927\n",
      "[75]\tvalid_0's l1: 0.0702985\n",
      "[76]\tvalid_0's l1: 0.0703011\n",
      "[77]\tvalid_0's l1: 0.0703021\n",
      "[78]\tvalid_0's l1: 0.0703035\n",
      "[79]\tvalid_0's l1: 0.0703025\n",
      "[80]\tvalid_0's l1: 0.0703002\n",
      "[81]\tvalid_0's l1: 0.0703008\n",
      "[82]\tvalid_0's l1: 0.0703017\n",
      "[83]\tvalid_0's l1: 0.0703002\n",
      "[84]\tvalid_0's l1: 0.0702984\n",
      "[85]\tvalid_0's l1: 0.0703002\n",
      "[86]\tvalid_0's l1: 0.0702968\n",
      "[87]\tvalid_0's l1: 0.0702979\n",
      "[88]\tvalid_0's l1: 0.0702915\n",
      "[89]\tvalid_0's l1: 0.0702842\n",
      "[90]\tvalid_0's l1: 0.0702855\n",
      "[91]\tvalid_0's l1: 0.0702795\n",
      "[92]\tvalid_0's l1: 0.0702772\n",
      "[93]\tvalid_0's l1: 0.0702757\n",
      "[94]\tvalid_0's l1: 0.0702732\n",
      "[95]\tvalid_0's l1: 0.0702741\n",
      "[96]\tvalid_0's l1: 0.0702759\n",
      "[97]\tvalid_0's l1: 0.0702727\n",
      "[98]\tvalid_0's l1: 0.0702749\n",
      "[99]\tvalid_0's l1: 0.0702712\n",
      "[100]\tvalid_0's l1: 0.0702739\n",
      "[101]\tvalid_0's l1: 0.0702752\n",
      "[102]\tvalid_0's l1: 0.0702717\n",
      "[103]\tvalid_0's l1: 0.0702782\n",
      "[104]\tvalid_0's l1: 0.0702796\n",
      "[105]\tvalid_0's l1: 0.0702729\n",
      "[106]\tvalid_0's l1: 0.0702711\n",
      "[107]\tvalid_0's l1: 0.0702711\n",
      "[108]\tvalid_0's l1: 0.0702739\n",
      "[109]\tvalid_0's l1: 0.0702715\n",
      "[110]\tvalid_0's l1: 0.0702754\n",
      "[111]\tvalid_0's l1: 0.0702769\n",
      "[112]\tvalid_0's l1: 0.0702775\n",
      "[113]\tvalid_0's l1: 0.0702789\n",
      "[114]\tvalid_0's l1: 0.0702788\n",
      "[115]\tvalid_0's l1: 0.0702764\n",
      "[116]\tvalid_0's l1: 0.0702732\n",
      "[117]\tvalid_0's l1: 0.0702701\n",
      "[118]\tvalid_0's l1: 0.0702697\n",
      "[119]\tvalid_0's l1: 0.070269\n",
      "[120]\tvalid_0's l1: 0.0702653\n",
      "[121]\tvalid_0's l1: 0.0702626\n",
      "[122]\tvalid_0's l1: 0.0702652\n",
      "[123]\tvalid_0's l1: 0.0702657\n",
      "[124]\tvalid_0's l1: 0.0702691\n",
      "[125]\tvalid_0's l1: 0.0702683\n",
      "[126]\tvalid_0's l1: 0.0702706\n",
      "[127]\tvalid_0's l1: 0.0702709\n",
      "[128]\tvalid_0's l1: 0.0702753\n",
      "[129]\tvalid_0's l1: 0.0702738\n",
      "[130]\tvalid_0's l1: 0.0702751\n",
      "[131]\tvalid_0's l1: 0.0702778\n",
      "[132]\tvalid_0's l1: 0.0702778\n",
      "[133]\tvalid_0's l1: 0.0702783\n",
      "[134]\tvalid_0's l1: 0.070282\n",
      "[135]\tvalid_0's l1: 0.0702819\n",
      "[136]\tvalid_0's l1: 0.0702837\n",
      "[137]\tvalid_0's l1: 0.0702846\n",
      "[138]\tvalid_0's l1: 0.0702858\n",
      "[139]\tvalid_0's l1: 0.0702867\n",
      "[140]\tvalid_0's l1: 0.0702869\n",
      "[141]\tvalid_0's l1: 0.0702845\n",
      "[142]\tvalid_0's l1: 0.0702871\n",
      "[143]\tvalid_0's l1: 0.0702934\n",
      "[144]\tvalid_0's l1: 0.0702963\n",
      "[145]\tvalid_0's l1: 0.0702945\n",
      "[146]\tvalid_0's l1: 0.0702916\n",
      "[147]\tvalid_0's l1: 0.0702924\n",
      "[148]\tvalid_0's l1: 0.0702927\n",
      "[149]\tvalid_0's l1: 0.0702962\n",
      "[150]\tvalid_0's l1: 0.0702945\n",
      "[151]\tvalid_0's l1: 0.0703042\n",
      "[152]\tvalid_0's l1: 0.0703062\n",
      "[153]\tvalid_0's l1: 0.0703089\n",
      "[154]\tvalid_0's l1: 0.070314\n",
      "[155]\tvalid_0's l1: 0.0703139\n",
      "[156]\tvalid_0's l1: 0.0703172\n",
      "[157]\tvalid_0's l1: 0.0703131\n",
      "[158]\tvalid_0's l1: 0.070309\n",
      "[159]\tvalid_0's l1: 0.0703113\n",
      "[160]\tvalid_0's l1: 0.0703139\n",
      "[161]\tvalid_0's l1: 0.0703144\n",
      "[162]\tvalid_0's l1: 0.0703146\n",
      "[163]\tvalid_0's l1: 0.070317\n",
      "[164]\tvalid_0's l1: 0.0703171\n",
      "[165]\tvalid_0's l1: 0.0703195\n",
      "[166]\tvalid_0's l1: 0.0703178\n",
      "[167]\tvalid_0's l1: 0.0703166\n",
      "[168]\tvalid_0's l1: 0.0703194\n",
      "[169]\tvalid_0's l1: 0.0703203\n",
      "[170]\tvalid_0's l1: 0.0703187\n",
      "[171]\tvalid_0's l1: 0.0703175\n",
      "[172]\tvalid_0's l1: 0.070321\n",
      "[173]\tvalid_0's l1: 0.0703207\n",
      "[174]\tvalid_0's l1: 0.0703205\n",
      "[175]\tvalid_0's l1: 0.0703156\n",
      "[176]\tvalid_0's l1: 0.0703123\n",
      "[177]\tvalid_0's l1: 0.0703079\n",
      "[178]\tvalid_0's l1: 0.0703026\n",
      "[179]\tvalid_0's l1: 0.0703006\n",
      "[180]\tvalid_0's l1: 0.0703008\n",
      "[181]\tvalid_0's l1: 0.0703021\n",
      "[182]\tvalid_0's l1: 0.0703058\n",
      "[183]\tvalid_0's l1: 0.0703049\n",
      "[184]\tvalid_0's l1: 0.0703078\n",
      "[185]\tvalid_0's l1: 0.0703102\n",
      "[186]\tvalid_0's l1: 0.07031\n",
      "[187]\tvalid_0's l1: 0.070309\n",
      "[188]\tvalid_0's l1: 0.0703111\n",
      "[189]\tvalid_0's l1: 0.0703073\n",
      "[190]\tvalid_0's l1: 0.0703067\n",
      "[191]\tvalid_0's l1: 0.0703011\n",
      "[192]\tvalid_0's l1: 0.0703036\n",
      "[193]\tvalid_0's l1: 0.0703027\n",
      "[194]\tvalid_0's l1: 0.070302\n",
      "[195]\tvalid_0's l1: 0.0703061\n",
      "[196]\tvalid_0's l1: 0.0703118\n",
      "[197]\tvalid_0's l1: 0.0703096\n",
      "[198]\tvalid_0's l1: 0.0703128\n",
      "[199]\tvalid_0's l1: 0.0703107\n",
      "[200]\tvalid_0's l1: 0.0703102\n",
      "[201]\tvalid_0's l1: 0.0703112\n",
      "[202]\tvalid_0's l1: 0.0703116\n",
      "[203]\tvalid_0's l1: 0.0703128\n",
      "[204]\tvalid_0's l1: 0.0703112\n",
      "[205]\tvalid_0's l1: 0.0703137\n",
      "[206]\tvalid_0's l1: 0.0703144\n",
      "[207]\tvalid_0's l1: 0.0703185\n",
      "[208]\tvalid_0's l1: 0.0703176\n",
      "[209]\tvalid_0's l1: 0.0703139\n",
      "[210]\tvalid_0's l1: 0.0703128\n",
      "[211]\tvalid_0's l1: 0.0703109\n",
      "[212]\tvalid_0's l1: 0.0703094\n",
      "[213]\tvalid_0's l1: 0.0703112\n",
      "[214]\tvalid_0's l1: 0.0703116\n",
      "[215]\tvalid_0's l1: 0.0703126\n",
      "[216]\tvalid_0's l1: 0.0703113\n",
      "[217]\tvalid_0's l1: 0.0703137\n",
      "[218]\tvalid_0's l1: 0.0703173\n",
      "[219]\tvalid_0's l1: 0.0703188\n",
      "[220]\tvalid_0's l1: 0.0703248\n",
      "[221]\tvalid_0's l1: 0.070327\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's l1: 0.0702626\n",
      "[1]\tvalid_0's l1: 0.0668638\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.06683\n",
      "[3]\tvalid_0's l1: 0.0667956\n",
      "[4]\tvalid_0's l1: 0.0667721\n",
      "[5]\tvalid_0's l1: 0.0667468\n",
      "[6]\tvalid_0's l1: 0.0667205\n",
      "[7]\tvalid_0's l1: 0.066698\n",
      "[8]\tvalid_0's l1: 0.0666682\n",
      "[9]\tvalid_0's l1: 0.0666397\n",
      "[10]\tvalid_0's l1: 0.0666251\n",
      "[11]\tvalid_0's l1: 0.0666048\n",
      "[12]\tvalid_0's l1: 0.0665829\n",
      "[13]\tvalid_0's l1: 0.0665595\n",
      "[14]\tvalid_0's l1: 0.0665412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\tvalid_0's l1: 0.0665234\n",
      "[16]\tvalid_0's l1: 0.0665066\n",
      "[17]\tvalid_0's l1: 0.0664909\n",
      "[18]\tvalid_0's l1: 0.0664884\n",
      "[19]\tvalid_0's l1: 0.0664705\n",
      "[20]\tvalid_0's l1: 0.0664565\n",
      "[21]\tvalid_0's l1: 0.0664358\n",
      "[22]\tvalid_0's l1: 0.066416\n",
      "[23]\tvalid_0's l1: 0.0663974\n",
      "[24]\tvalid_0's l1: 0.0663819\n",
      "[25]\tvalid_0's l1: 0.0663673\n",
      "[26]\tvalid_0's l1: 0.0663551\n",
      "[27]\tvalid_0's l1: 0.0663436\n",
      "[28]\tvalid_0's l1: 0.0663353\n",
      "[29]\tvalid_0's l1: 0.066325\n",
      "[30]\tvalid_0's l1: 0.0663134\n",
      "[31]\tvalid_0's l1: 0.0663029\n",
      "[32]\tvalid_0's l1: 0.0662977\n",
      "[33]\tvalid_0's l1: 0.0662908\n",
      "[34]\tvalid_0's l1: 0.0662864\n",
      "[35]\tvalid_0's l1: 0.0662877\n",
      "[36]\tvalid_0's l1: 0.0662878\n",
      "[37]\tvalid_0's l1: 0.0662837\n",
      "[38]\tvalid_0's l1: 0.066276\n",
      "[39]\tvalid_0's l1: 0.0662678\n",
      "[40]\tvalid_0's l1: 0.0662657\n",
      "[41]\tvalid_0's l1: 0.0662608\n",
      "[42]\tvalid_0's l1: 0.0662534\n",
      "[43]\tvalid_0's l1: 0.0662471\n",
      "[44]\tvalid_0's l1: 0.0662462\n",
      "[45]\tvalid_0's l1: 0.0662415\n",
      "[46]\tvalid_0's l1: 0.0662387\n",
      "[47]\tvalid_0's l1: 0.0662306\n",
      "[48]\tvalid_0's l1: 0.0662253\n",
      "[49]\tvalid_0's l1: 0.0662213\n",
      "[50]\tvalid_0's l1: 0.0662207\n",
      "[51]\tvalid_0's l1: 0.0662162\n",
      "[52]\tvalid_0's l1: 0.0662127\n",
      "[53]\tvalid_0's l1: 0.0662097\n",
      "[54]\tvalid_0's l1: 0.0662082\n",
      "[55]\tvalid_0's l1: 0.0662045\n",
      "[56]\tvalid_0's l1: 0.0662018\n",
      "[57]\tvalid_0's l1: 0.0662029\n",
      "[58]\tvalid_0's l1: 0.0662015\n",
      "[59]\tvalid_0's l1: 0.0662001\n",
      "[60]\tvalid_0's l1: 0.0661966\n",
      "[61]\tvalid_0's l1: 0.0661961\n",
      "[62]\tvalid_0's l1: 0.0661903\n",
      "[63]\tvalid_0's l1: 0.0661871\n",
      "[64]\tvalid_0's l1: 0.0661855\n",
      "[65]\tvalid_0's l1: 0.0661862\n",
      "[66]\tvalid_0's l1: 0.066185\n",
      "[67]\tvalid_0's l1: 0.0661813\n",
      "[68]\tvalid_0's l1: 0.066181\n",
      "[69]\tvalid_0's l1: 0.0661804\n",
      "[70]\tvalid_0's l1: 0.0661788\n",
      "[71]\tvalid_0's l1: 0.0661826\n",
      "[72]\tvalid_0's l1: 0.0661792\n",
      "[73]\tvalid_0's l1: 0.0661823\n",
      "[74]\tvalid_0's l1: 0.066183\n",
      "[75]\tvalid_0's l1: 0.0661836\n",
      "[76]\tvalid_0's l1: 0.0661783\n",
      "[77]\tvalid_0's l1: 0.0661731\n",
      "[78]\tvalid_0's l1: 0.066171\n",
      "[79]\tvalid_0's l1: 0.0661679\n",
      "[80]\tvalid_0's l1: 0.0661682\n",
      "[81]\tvalid_0's l1: 0.0661642\n",
      "[82]\tvalid_0's l1: 0.0661653\n",
      "[83]\tvalid_0's l1: 0.0661722\n",
      "[84]\tvalid_0's l1: 0.066171\n",
      "[85]\tvalid_0's l1: 0.0661729\n",
      "[86]\tvalid_0's l1: 0.0661739\n",
      "[87]\tvalid_0's l1: 0.0661786\n",
      "[88]\tvalid_0's l1: 0.0661824\n",
      "[89]\tvalid_0's l1: 0.0661807\n",
      "[90]\tvalid_0's l1: 0.0661805\n",
      "[91]\tvalid_0's l1: 0.0661833\n",
      "[92]\tvalid_0's l1: 0.0661879\n",
      "[93]\tvalid_0's l1: 0.06619\n",
      "[94]\tvalid_0's l1: 0.0661873\n",
      "[95]\tvalid_0's l1: 0.0661867\n",
      "[96]\tvalid_0's l1: 0.0661868\n",
      "[97]\tvalid_0's l1: 0.0661907\n",
      "[98]\tvalid_0's l1: 0.0661941\n",
      "[99]\tvalid_0's l1: 0.0661933\n",
      "[100]\tvalid_0's l1: 0.0661941\n",
      "[101]\tvalid_0's l1: 0.0661937\n",
      "[102]\tvalid_0's l1: 0.0661926\n",
      "[103]\tvalid_0's l1: 0.0661939\n",
      "[104]\tvalid_0's l1: 0.0661961\n",
      "[105]\tvalid_0's l1: 0.0661987\n",
      "[106]\tvalid_0's l1: 0.0662024\n",
      "[107]\tvalid_0's l1: 0.0662071\n",
      "[108]\tvalid_0's l1: 0.0662097\n",
      "[109]\tvalid_0's l1: 0.0662129\n",
      "[110]\tvalid_0's l1: 0.0662132\n",
      "[111]\tvalid_0's l1: 0.0662155\n",
      "[112]\tvalid_0's l1: 0.0662148\n",
      "[113]\tvalid_0's l1: 0.0662187\n",
      "[114]\tvalid_0's l1: 0.0662179\n",
      "[115]\tvalid_0's l1: 0.0662208\n",
      "[116]\tvalid_0's l1: 0.0662261\n",
      "[117]\tvalid_0's l1: 0.0662245\n",
      "[118]\tvalid_0's l1: 0.0662264\n",
      "[119]\tvalid_0's l1: 0.0662259\n",
      "[120]\tvalid_0's l1: 0.0662274\n",
      "[121]\tvalid_0's l1: 0.0662252\n",
      "[122]\tvalid_0's l1: 0.0662233\n",
      "[123]\tvalid_0's l1: 0.0662235\n",
      "[124]\tvalid_0's l1: 0.066221\n",
      "[125]\tvalid_0's l1: 0.06622\n",
      "[126]\tvalid_0's l1: 0.0662183\n",
      "[127]\tvalid_0's l1: 0.0662172\n",
      "[128]\tvalid_0's l1: 0.0662178\n",
      "[129]\tvalid_0's l1: 0.0662126\n",
      "[130]\tvalid_0's l1: 0.0662119\n",
      "[131]\tvalid_0's l1: 0.0662126\n",
      "[132]\tvalid_0's l1: 0.0662166\n",
      "[133]\tvalid_0's l1: 0.06621\n",
      "[134]\tvalid_0's l1: 0.0662134\n",
      "[135]\tvalid_0's l1: 0.0662124\n",
      "[136]\tvalid_0's l1: 0.0662164\n",
      "[137]\tvalid_0's l1: 0.0662249\n",
      "[138]\tvalid_0's l1: 0.0662257\n",
      "[139]\tvalid_0's l1: 0.066225\n",
      "[140]\tvalid_0's l1: 0.0662283\n",
      "[141]\tvalid_0's l1: 0.066232\n",
      "[142]\tvalid_0's l1: 0.0662347\n",
      "[143]\tvalid_0's l1: 0.06624\n",
      "[144]\tvalid_0's l1: 0.0662436\n",
      "[145]\tvalid_0's l1: 0.0662434\n",
      "[146]\tvalid_0's l1: 0.066243\n",
      "[147]\tvalid_0's l1: 0.0662453\n",
      "[148]\tvalid_0's l1: 0.0662489\n",
      "[149]\tvalid_0's l1: 0.0662532\n",
      "[150]\tvalid_0's l1: 0.0662553\n",
      "[151]\tvalid_0's l1: 0.0662605\n",
      "[152]\tvalid_0's l1: 0.0662647\n",
      "[153]\tvalid_0's l1: 0.0662625\n",
      "[154]\tvalid_0's l1: 0.0662658\n",
      "[155]\tvalid_0's l1: 0.0662691\n",
      "[156]\tvalid_0's l1: 0.066273\n",
      "[157]\tvalid_0's l1: 0.0662788\n",
      "[158]\tvalid_0's l1: 0.0662846\n",
      "[159]\tvalid_0's l1: 0.0662882\n",
      "[160]\tvalid_0's l1: 0.0662915\n",
      "[161]\tvalid_0's l1: 0.066291\n",
      "[162]\tvalid_0's l1: 0.0662897\n",
      "[163]\tvalid_0's l1: 0.0662894\n",
      "[164]\tvalid_0's l1: 0.0662909\n",
      "[165]\tvalid_0's l1: 0.0662844\n",
      "[166]\tvalid_0's l1: 0.0662825\n",
      "[167]\tvalid_0's l1: 0.0662869\n",
      "[168]\tvalid_0's l1: 0.0662901\n",
      "[169]\tvalid_0's l1: 0.0662919\n",
      "[170]\tvalid_0's l1: 0.0662914\n",
      "[171]\tvalid_0's l1: 0.0662857\n",
      "[172]\tvalid_0's l1: 0.0662854\n",
      "[173]\tvalid_0's l1: 0.0662856\n",
      "[174]\tvalid_0's l1: 0.0662858\n",
      "[175]\tvalid_0's l1: 0.0662853\n",
      "[176]\tvalid_0's l1: 0.0662826\n",
      "[177]\tvalid_0's l1: 0.0662846\n",
      "[178]\tvalid_0's l1: 0.0662803\n",
      "[179]\tvalid_0's l1: 0.0662794\n",
      "[180]\tvalid_0's l1: 0.0662803\n",
      "[181]\tvalid_0's l1: 0.0662838\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's l1: 0.0661642\n",
      "[1]\tvalid_0's l1: 0.068931\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0689039\n",
      "[3]\tvalid_0's l1: 0.0688804\n",
      "[4]\tvalid_0's l1: 0.0688548\n",
      "[5]\tvalid_0's l1: 0.0688323\n",
      "[6]\tvalid_0's l1: 0.0688103\n",
      "[7]\tvalid_0's l1: 0.0687969\n",
      "[8]\tvalid_0's l1: 0.0687715\n",
      "[9]\tvalid_0's l1: 0.068751\n",
      "[10]\tvalid_0's l1: 0.0687391\n",
      "[11]\tvalid_0's l1: 0.0687128\n",
      "[12]\tvalid_0's l1: 0.068689\n",
      "[13]\tvalid_0's l1: 0.0686673\n",
      "[14]\tvalid_0's l1: 0.0686478\n",
      "[15]\tvalid_0's l1: 0.0686294\n",
      "[16]\tvalid_0's l1: 0.0686186\n",
      "[17]\tvalid_0's l1: 0.0686052\n",
      "[18]\tvalid_0's l1: 0.0686007\n",
      "[19]\tvalid_0's l1: 0.0685936\n",
      "[20]\tvalid_0's l1: 0.068579\n",
      "[21]\tvalid_0's l1: 0.0685597\n",
      "[22]\tvalid_0's l1: 0.0685449\n",
      "[23]\tvalid_0's l1: 0.0685315\n",
      "[24]\tvalid_0's l1: 0.0685197\n",
      "[25]\tvalid_0's l1: 0.0685053\n",
      "[26]\tvalid_0's l1: 0.0684949\n",
      "[27]\tvalid_0's l1: 0.068484\n",
      "[28]\tvalid_0's l1: 0.0684782\n",
      "[29]\tvalid_0's l1: 0.06847\n",
      "[30]\tvalid_0's l1: 0.0684646\n",
      "[31]\tvalid_0's l1: 0.0684532\n",
      "[32]\tvalid_0's l1: 0.0684443\n",
      "[33]\tvalid_0's l1: 0.0684374\n",
      "[34]\tvalid_0's l1: 0.0684281\n",
      "[35]\tvalid_0's l1: 0.0684251\n",
      "[36]\tvalid_0's l1: 0.0684235\n",
      "[37]\tvalid_0's l1: 0.0684231\n",
      "[38]\tvalid_0's l1: 0.0684177\n",
      "[39]\tvalid_0's l1: 0.0684133\n",
      "[40]\tvalid_0's l1: 0.0684051\n",
      "[41]\tvalid_0's l1: 0.068402\n",
      "[42]\tvalid_0's l1: 0.0683969\n",
      "[43]\tvalid_0's l1: 0.0683941\n",
      "[44]\tvalid_0's l1: 0.0683925\n",
      "[45]\tvalid_0's l1: 0.0683879\n",
      "[46]\tvalid_0's l1: 0.0683848\n",
      "[47]\tvalid_0's l1: 0.0683818\n",
      "[48]\tvalid_0's l1: 0.0683771\n",
      "[49]\tvalid_0's l1: 0.0683723\n",
      "[50]\tvalid_0's l1: 0.0683639\n",
      "[51]\tvalid_0's l1: 0.0683619\n",
      "[52]\tvalid_0's l1: 0.0683611\n",
      "[53]\tvalid_0's l1: 0.0683606\n",
      "[54]\tvalid_0's l1: 0.0683611\n",
      "[55]\tvalid_0's l1: 0.0683568\n",
      "[56]\tvalid_0's l1: 0.0683614\n",
      "[57]\tvalid_0's l1: 0.0683627\n",
      "[58]\tvalid_0's l1: 0.0683537\n",
      "[59]\tvalid_0's l1: 0.0683565\n",
      "[60]\tvalid_0's l1: 0.0683571\n",
      "[61]\tvalid_0's l1: 0.0683554\n",
      "[62]\tvalid_0's l1: 0.0683482\n",
      "[63]\tvalid_0's l1: 0.0683463\n",
      "[64]\tvalid_0's l1: 0.0683493\n",
      "[65]\tvalid_0's l1: 0.0683508\n",
      "[66]\tvalid_0's l1: 0.0683521\n",
      "[67]\tvalid_0's l1: 0.0683531\n",
      "[68]\tvalid_0's l1: 0.068353\n",
      "[69]\tvalid_0's l1: 0.0683524\n",
      "[70]\tvalid_0's l1: 0.0683563\n",
      "[71]\tvalid_0's l1: 0.0683582\n",
      "[72]\tvalid_0's l1: 0.068359\n",
      "[73]\tvalid_0's l1: 0.0683613\n",
      "[74]\tvalid_0's l1: 0.0683635\n",
      "[75]\tvalid_0's l1: 0.0683683\n",
      "[76]\tvalid_0's l1: 0.0683692\n",
      "[77]\tvalid_0's l1: 0.0683691\n",
      "[78]\tvalid_0's l1: 0.0683695\n",
      "[79]\tvalid_0's l1: 0.0683728\n",
      "[80]\tvalid_0's l1: 0.0683763\n",
      "[81]\tvalid_0's l1: 0.0683741\n",
      "[82]\tvalid_0's l1: 0.0683686\n",
      "[83]\tvalid_0's l1: 0.068365\n",
      "[84]\tvalid_0's l1: 0.0683594\n",
      "[85]\tvalid_0's l1: 0.0683567\n",
      "[86]\tvalid_0's l1: 0.0683564\n",
      "[87]\tvalid_0's l1: 0.0683579\n",
      "[88]\tvalid_0's l1: 0.0683625\n",
      "[89]\tvalid_0's l1: 0.068361\n",
      "[90]\tvalid_0's l1: 0.068358\n",
      "[91]\tvalid_0's l1: 0.0683575\n",
      "[92]\tvalid_0's l1: 0.0683548\n",
      "[93]\tvalid_0's l1: 0.0683566\n",
      "[94]\tvalid_0's l1: 0.0683592\n",
      "[95]\tvalid_0's l1: 0.0683552\n",
      "[96]\tvalid_0's l1: 0.0683546\n",
      "[97]\tvalid_0's l1: 0.0683552\n",
      "[98]\tvalid_0's l1: 0.0683584\n",
      "[99]\tvalid_0's l1: 0.068355\n",
      "[100]\tvalid_0's l1: 0.0683571\n",
      "[101]\tvalid_0's l1: 0.0683562\n",
      "[102]\tvalid_0's l1: 0.0683542\n",
      "[103]\tvalid_0's l1: 0.0683512\n",
      "[104]\tvalid_0's l1: 0.0683531\n",
      "[105]\tvalid_0's l1: 0.0683531\n",
      "[106]\tvalid_0's l1: 0.0683444\n",
      "[107]\tvalid_0's l1: 0.0683398\n",
      "[108]\tvalid_0's l1: 0.0683376\n",
      "[109]\tvalid_0's l1: 0.0683374\n",
      "[110]\tvalid_0's l1: 0.068336\n",
      "[111]\tvalid_0's l1: 0.0683346\n",
      "[112]\tvalid_0's l1: 0.0683348\n",
      "[113]\tvalid_0's l1: 0.0683326\n",
      "[114]\tvalid_0's l1: 0.0683287\n",
      "[115]\tvalid_0's l1: 0.0683298\n",
      "[116]\tvalid_0's l1: 0.0683295\n",
      "[117]\tvalid_0's l1: 0.0683304\n",
      "[118]\tvalid_0's l1: 0.0683255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119]\tvalid_0's l1: 0.0683259\n",
      "[120]\tvalid_0's l1: 0.0683241\n",
      "[121]\tvalid_0's l1: 0.0683224\n",
      "[122]\tvalid_0's l1: 0.0683214\n",
      "[123]\tvalid_0's l1: 0.0683225\n",
      "[124]\tvalid_0's l1: 0.0683254\n",
      "[125]\tvalid_0's l1: 0.0683259\n",
      "[126]\tvalid_0's l1: 0.0683264\n",
      "[127]\tvalid_0's l1: 0.068322\n",
      "[128]\tvalid_0's l1: 0.0683226\n",
      "[129]\tvalid_0's l1: 0.0683217\n",
      "[130]\tvalid_0's l1: 0.0683233\n",
      "[131]\tvalid_0's l1: 0.0683268\n",
      "[132]\tvalid_0's l1: 0.0683257\n",
      "[133]\tvalid_0's l1: 0.0683281\n",
      "[134]\tvalid_0's l1: 0.0683196\n",
      "[135]\tvalid_0's l1: 0.0683222\n",
      "[136]\tvalid_0's l1: 0.0683269\n",
      "[137]\tvalid_0's l1: 0.0683304\n",
      "[138]\tvalid_0's l1: 0.0683331\n",
      "[139]\tvalid_0's l1: 0.068337\n",
      "[140]\tvalid_0's l1: 0.0683394\n",
      "[141]\tvalid_0's l1: 0.0683419\n",
      "[142]\tvalid_0's l1: 0.0683362\n",
      "[143]\tvalid_0's l1: 0.0683402\n",
      "[144]\tvalid_0's l1: 0.0683422\n",
      "[145]\tvalid_0's l1: 0.0683421\n",
      "[146]\tvalid_0's l1: 0.0683393\n",
      "[147]\tvalid_0's l1: 0.0683403\n",
      "[148]\tvalid_0's l1: 0.0683438\n",
      "[149]\tvalid_0's l1: 0.0683459\n",
      "[150]\tvalid_0's l1: 0.0683479\n",
      "[151]\tvalid_0's l1: 0.0683534\n",
      "[152]\tvalid_0's l1: 0.0683551\n",
      "[153]\tvalid_0's l1: 0.0683574\n",
      "[154]\tvalid_0's l1: 0.0683622\n",
      "[155]\tvalid_0's l1: 0.0683594\n",
      "[156]\tvalid_0's l1: 0.0683529\n",
      "[157]\tvalid_0's l1: 0.0683491\n",
      "[158]\tvalid_0's l1: 0.0683455\n",
      "[159]\tvalid_0's l1: 0.0683443\n",
      "[160]\tvalid_0's l1: 0.0683443\n",
      "[161]\tvalid_0's l1: 0.0683435\n",
      "[162]\tvalid_0's l1: 0.0683453\n",
      "[163]\tvalid_0's l1: 0.0683489\n",
      "[164]\tvalid_0's l1: 0.0683527\n",
      "[165]\tvalid_0's l1: 0.0683526\n",
      "[166]\tvalid_0's l1: 0.0683558\n",
      "[167]\tvalid_0's l1: 0.0683553\n",
      "[168]\tvalid_0's l1: 0.0683539\n",
      "[169]\tvalid_0's l1: 0.0683563\n",
      "[170]\tvalid_0's l1: 0.0683578\n",
      "[171]\tvalid_0's l1: 0.0683564\n",
      "[172]\tvalid_0's l1: 0.0683564\n",
      "[173]\tvalid_0's l1: 0.0683587\n",
      "[174]\tvalid_0's l1: 0.0683588\n",
      "[175]\tvalid_0's l1: 0.0683609\n",
      "[176]\tvalid_0's l1: 0.0683583\n",
      "[177]\tvalid_0's l1: 0.0683534\n",
      "[178]\tvalid_0's l1: 0.0683517\n",
      "[179]\tvalid_0's l1: 0.0683537\n",
      "[180]\tvalid_0's l1: 0.0683532\n",
      "[181]\tvalid_0's l1: 0.0683555\n",
      "[182]\tvalid_0's l1: 0.0683565\n",
      "[183]\tvalid_0's l1: 0.068356\n",
      "[184]\tvalid_0's l1: 0.0683549\n",
      "[185]\tvalid_0's l1: 0.0683561\n",
      "[186]\tvalid_0's l1: 0.0683576\n",
      "[187]\tvalid_0's l1: 0.0683588\n",
      "[188]\tvalid_0's l1: 0.0683588\n",
      "[189]\tvalid_0's l1: 0.0683619\n",
      "[190]\tvalid_0's l1: 0.0683607\n",
      "[191]\tvalid_0's l1: 0.0683638\n",
      "[192]\tvalid_0's l1: 0.0683712\n",
      "[193]\tvalid_0's l1: 0.0683737\n",
      "[194]\tvalid_0's l1: 0.068376\n",
      "[195]\tvalid_0's l1: 0.0683783\n",
      "[196]\tvalid_0's l1: 0.0683771\n",
      "[197]\tvalid_0's l1: 0.0683778\n",
      "[198]\tvalid_0's l1: 0.0683785\n",
      "[199]\tvalid_0's l1: 0.0683706\n",
      "[200]\tvalid_0's l1: 0.0683703\n",
      "[201]\tvalid_0's l1: 0.0683684\n",
      "[202]\tvalid_0's l1: 0.0683696\n",
      "[203]\tvalid_0's l1: 0.0683686\n",
      "[204]\tvalid_0's l1: 0.0683695\n",
      "[205]\tvalid_0's l1: 0.0683702\n",
      "[206]\tvalid_0's l1: 0.0683659\n",
      "[207]\tvalid_0's l1: 0.0683682\n",
      "[208]\tvalid_0's l1: 0.0683719\n",
      "[209]\tvalid_0's l1: 0.068375\n",
      "[210]\tvalid_0's l1: 0.0683751\n",
      "[211]\tvalid_0's l1: 0.0683708\n",
      "[212]\tvalid_0's l1: 0.0683717\n",
      "[213]\tvalid_0's l1: 0.068372\n",
      "[214]\tvalid_0's l1: 0.0683706\n",
      "[215]\tvalid_0's l1: 0.0683739\n",
      "[216]\tvalid_0's l1: 0.0683743\n",
      "[217]\tvalid_0's l1: 0.0683802\n",
      "[218]\tvalid_0's l1: 0.0683823\n",
      "[219]\tvalid_0's l1: 0.0683859\n",
      "[220]\tvalid_0's l1: 0.0683889\n",
      "[221]\tvalid_0's l1: 0.0683929\n",
      "[222]\tvalid_0's l1: 0.0683919\n",
      "[223]\tvalid_0's l1: 0.0683952\n",
      "[224]\tvalid_0's l1: 0.0683973\n",
      "[225]\tvalid_0's l1: 0.0684005\n",
      "[226]\tvalid_0's l1: 0.0684037\n",
      "[227]\tvalid_0's l1: 0.0684042\n",
      "[228]\tvalid_0's l1: 0.0684081\n",
      "[229]\tvalid_0's l1: 0.0684069\n",
      "[230]\tvalid_0's l1: 0.0684061\n",
      "[231]\tvalid_0's l1: 0.0684073\n",
      "[232]\tvalid_0's l1: 0.0684057\n",
      "[233]\tvalid_0's l1: 0.0684066\n",
      "[234]\tvalid_0's l1: 0.0684032\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's l1: 0.0683196\n",
      "[1]\tvalid_0's l1: 0.063936\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0639078\n",
      "[3]\tvalid_0's l1: 0.0638811\n",
      "[4]\tvalid_0's l1: 0.0638552\n",
      "[5]\tvalid_0's l1: 0.063834\n",
      "[6]\tvalid_0's l1: 0.063809\n",
      "[7]\tvalid_0's l1: 0.0637861\n",
      "[8]\tvalid_0's l1: 0.0637677\n",
      "[9]\tvalid_0's l1: 0.0637512\n",
      "[10]\tvalid_0's l1: 0.0637353\n",
      "[11]\tvalid_0's l1: 0.0637218\n",
      "[12]\tvalid_0's l1: 0.0637115\n",
      "[13]\tvalid_0's l1: 0.0636964\n",
      "[14]\tvalid_0's l1: 0.0636899\n",
      "[15]\tvalid_0's l1: 0.063688\n",
      "[16]\tvalid_0's l1: 0.0636825\n",
      "[17]\tvalid_0's l1: 0.0636747\n",
      "[18]\tvalid_0's l1: 0.0636664\n",
      "[19]\tvalid_0's l1: 0.0636669\n",
      "[20]\tvalid_0's l1: 0.0636616\n",
      "[21]\tvalid_0's l1: 0.0636523\n",
      "[22]\tvalid_0's l1: 0.0636429\n",
      "[23]\tvalid_0's l1: 0.0636314\n",
      "[24]\tvalid_0's l1: 0.063628\n",
      "[25]\tvalid_0's l1: 0.0636224\n",
      "[26]\tvalid_0's l1: 0.0636134\n",
      "[27]\tvalid_0's l1: 0.0636135\n",
      "[28]\tvalid_0's l1: 0.0636053\n",
      "[29]\tvalid_0's l1: 0.0636049\n",
      "[30]\tvalid_0's l1: 0.0635979\n",
      "[31]\tvalid_0's l1: 0.0635946\n",
      "[32]\tvalid_0's l1: 0.063588\n",
      "[33]\tvalid_0's l1: 0.0635868\n",
      "[34]\tvalid_0's l1: 0.063581\n",
      "[35]\tvalid_0's l1: 0.0635732\n",
      "[36]\tvalid_0's l1: 0.0635699\n",
      "[37]\tvalid_0's l1: 0.0635666\n",
      "[38]\tvalid_0's l1: 0.0635681\n",
      "[39]\tvalid_0's l1: 0.0635679\n",
      "[40]\tvalid_0's l1: 0.0635606\n",
      "[41]\tvalid_0's l1: 0.0635587\n",
      "[42]\tvalid_0's l1: 0.0635541\n",
      "[43]\tvalid_0's l1: 0.0635561\n",
      "[44]\tvalid_0's l1: 0.0635569\n",
      "[45]\tvalid_0's l1: 0.0635531\n",
      "[46]\tvalid_0's l1: 0.0635484\n",
      "[47]\tvalid_0's l1: 0.0635465\n",
      "[48]\tvalid_0's l1: 0.0635448\n",
      "[49]\tvalid_0's l1: 0.063546\n",
      "[50]\tvalid_0's l1: 0.0635426\n",
      "[51]\tvalid_0's l1: 0.0635448\n",
      "[52]\tvalid_0's l1: 0.0635492\n",
      "[53]\tvalid_0's l1: 0.0635528\n",
      "[54]\tvalid_0's l1: 0.0635515\n",
      "[55]\tvalid_0's l1: 0.0635566\n",
      "[56]\tvalid_0's l1: 0.0635593\n",
      "[57]\tvalid_0's l1: 0.0635559\n",
      "[58]\tvalid_0's l1: 0.0635533\n",
      "[59]\tvalid_0's l1: 0.0635519\n",
      "[60]\tvalid_0's l1: 0.063546\n",
      "[61]\tvalid_0's l1: 0.0635501\n",
      "[62]\tvalid_0's l1: 0.0635518\n",
      "[63]\tvalid_0's l1: 0.063558\n",
      "[64]\tvalid_0's l1: 0.0635581\n",
      "[65]\tvalid_0's l1: 0.0635632\n",
      "[66]\tvalid_0's l1: 0.0635595\n",
      "[67]\tvalid_0's l1: 0.0635618\n",
      "[68]\tvalid_0's l1: 0.0635616\n",
      "[69]\tvalid_0's l1: 0.0635627\n",
      "[70]\tvalid_0's l1: 0.0635627\n",
      "[71]\tvalid_0's l1: 0.0635613\n",
      "[72]\tvalid_0's l1: 0.0635582\n",
      "[73]\tvalid_0's l1: 0.0635602\n",
      "[74]\tvalid_0's l1: 0.0635584\n",
      "[75]\tvalid_0's l1: 0.0635579\n",
      "[76]\tvalid_0's l1: 0.0635571\n",
      "[77]\tvalid_0's l1: 0.0635604\n",
      "[78]\tvalid_0's l1: 0.0635589\n",
      "[79]\tvalid_0's l1: 0.063559\n",
      "[80]\tvalid_0's l1: 0.0635631\n",
      "[81]\tvalid_0's l1: 0.063563\n",
      "[82]\tvalid_0's l1: 0.0635648\n",
      "[83]\tvalid_0's l1: 0.0635708\n",
      "[84]\tvalid_0's l1: 0.0635721\n",
      "[85]\tvalid_0's l1: 0.0635716\n",
      "[86]\tvalid_0's l1: 0.0635718\n",
      "[87]\tvalid_0's l1: 0.0635735\n",
      "[88]\tvalid_0's l1: 0.0635719\n",
      "[89]\tvalid_0's l1: 0.0635645\n",
      "[90]\tvalid_0's l1: 0.0635652\n",
      "[91]\tvalid_0's l1: 0.0635646\n",
      "[92]\tvalid_0's l1: 0.0635643\n",
      "[93]\tvalid_0's l1: 0.063559\n",
      "[94]\tvalid_0's l1: 0.0635566\n",
      "[95]\tvalid_0's l1: 0.0635552\n",
      "[96]\tvalid_0's l1: 0.0635542\n",
      "[97]\tvalid_0's l1: 0.0635522\n",
      "[98]\tvalid_0's l1: 0.0635537\n",
      "[99]\tvalid_0's l1: 0.0635596\n",
      "[100]\tvalid_0's l1: 0.0635616\n",
      "[101]\tvalid_0's l1: 0.0635617\n",
      "[102]\tvalid_0's l1: 0.0635614\n",
      "[103]\tvalid_0's l1: 0.0635654\n",
      "[104]\tvalid_0's l1: 0.0635639\n",
      "[105]\tvalid_0's l1: 0.0635665\n",
      "[106]\tvalid_0's l1: 0.0635685\n",
      "[107]\tvalid_0's l1: 0.0635685\n",
      "[108]\tvalid_0's l1: 0.0635682\n",
      "[109]\tvalid_0's l1: 0.0635651\n",
      "[110]\tvalid_0's l1: 0.0635678\n",
      "[111]\tvalid_0's l1: 0.063568\n",
      "[112]\tvalid_0's l1: 0.063569\n",
      "[113]\tvalid_0's l1: 0.0635727\n",
      "[114]\tvalid_0's l1: 0.0635747\n",
      "[115]\tvalid_0's l1: 0.0635724\n",
      "[116]\tvalid_0's l1: 0.0635748\n",
      "[117]\tvalid_0's l1: 0.0635749\n",
      "[118]\tvalid_0's l1: 0.0635763\n",
      "[119]\tvalid_0's l1: 0.063577\n",
      "[120]\tvalid_0's l1: 0.0635737\n",
      "[121]\tvalid_0's l1: 0.0635789\n",
      "[122]\tvalid_0's l1: 0.0635848\n",
      "[123]\tvalid_0's l1: 0.0635844\n",
      "[124]\tvalid_0's l1: 0.0635849\n",
      "[125]\tvalid_0's l1: 0.0635819\n",
      "[126]\tvalid_0's l1: 0.0635812\n",
      "[127]\tvalid_0's l1: 0.063581\n",
      "[128]\tvalid_0's l1: 0.0635791\n",
      "[129]\tvalid_0's l1: 0.0635731\n",
      "[130]\tvalid_0's l1: 0.0635712\n",
      "[131]\tvalid_0's l1: 0.0635711\n",
      "[132]\tvalid_0's l1: 0.0635759\n",
      "[133]\tvalid_0's l1: 0.0635746\n",
      "[134]\tvalid_0's l1: 0.0635724\n",
      "[135]\tvalid_0's l1: 0.0635724\n",
      "[136]\tvalid_0's l1: 0.0635747\n",
      "[137]\tvalid_0's l1: 0.0635767\n",
      "[138]\tvalid_0's l1: 0.0635752\n",
      "[139]\tvalid_0's l1: 0.0635718\n",
      "[140]\tvalid_0's l1: 0.06358\n",
      "[141]\tvalid_0's l1: 0.0635837\n",
      "[142]\tvalid_0's l1: 0.0635888\n",
      "[143]\tvalid_0's l1: 0.0635946\n",
      "[144]\tvalid_0's l1: 0.0635994\n",
      "[145]\tvalid_0's l1: 0.063599\n",
      "[146]\tvalid_0's l1: 0.0635972\n",
      "[147]\tvalid_0's l1: 0.063595\n",
      "[148]\tvalid_0's l1: 0.0635958\n",
      "[149]\tvalid_0's l1: 0.0635985\n",
      "[150]\tvalid_0's l1: 0.0636003\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's l1: 0.0635426\n",
      "[1]\tvalid_0's l1: 0.0652965\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0652674\n",
      "[3]\tvalid_0's l1: 0.0652327\n",
      "[4]\tvalid_0's l1: 0.0652043\n",
      "[5]\tvalid_0's l1: 0.0651784\n",
      "[6]\tvalid_0's l1: 0.0651569\n",
      "[7]\tvalid_0's l1: 0.065133\n",
      "[8]\tvalid_0's l1: 0.0651015\n",
      "[9]\tvalid_0's l1: 0.0650788\n",
      "[10]\tvalid_0's l1: 0.0650626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\tvalid_0's l1: 0.0650401\n",
      "[12]\tvalid_0's l1: 0.0650197\n",
      "[13]\tvalid_0's l1: 0.0650005\n",
      "[14]\tvalid_0's l1: 0.0649803\n",
      "[15]\tvalid_0's l1: 0.0649655\n",
      "[16]\tvalid_0's l1: 0.0649551\n",
      "[17]\tvalid_0's l1: 0.0649473\n",
      "[18]\tvalid_0's l1: 0.0649401\n",
      "[19]\tvalid_0's l1: 0.0649283\n",
      "[20]\tvalid_0's l1: 0.0649243\n",
      "[21]\tvalid_0's l1: 0.0649099\n",
      "[22]\tvalid_0's l1: 0.0649022\n",
      "[23]\tvalid_0's l1: 0.0648915\n",
      "[24]\tvalid_0's l1: 0.064882\n",
      "[25]\tvalid_0's l1: 0.0648713\n",
      "[26]\tvalid_0's l1: 0.0648548\n",
      "[27]\tvalid_0's l1: 0.0648486\n",
      "[28]\tvalid_0's l1: 0.0648442\n",
      "[29]\tvalid_0's l1: 0.0648305\n",
      "[30]\tvalid_0's l1: 0.0648189\n",
      "[31]\tvalid_0's l1: 0.0648139\n",
      "[32]\tvalid_0's l1: 0.0648098\n",
      "[33]\tvalid_0's l1: 0.0647992\n",
      "[34]\tvalid_0's l1: 0.0647915\n",
      "[35]\tvalid_0's l1: 0.0647891\n",
      "[36]\tvalid_0's l1: 0.0647805\n",
      "[37]\tvalid_0's l1: 0.0647729\n",
      "[38]\tvalid_0's l1: 0.0647585\n",
      "[39]\tvalid_0's l1: 0.0647521\n",
      "[40]\tvalid_0's l1: 0.0647498\n",
      "[41]\tvalid_0's l1: 0.0647416\n",
      "[42]\tvalid_0's l1: 0.06474\n",
      "[43]\tvalid_0's l1: 0.0647345\n",
      "[44]\tvalid_0's l1: 0.0647303\n",
      "[45]\tvalid_0's l1: 0.064722\n",
      "[46]\tvalid_0's l1: 0.0647202\n",
      "[47]\tvalid_0's l1: 0.0647234\n",
      "[48]\tvalid_0's l1: 0.0647246\n",
      "[49]\tvalid_0's l1: 0.0647264\n",
      "[50]\tvalid_0's l1: 0.0647278\n",
      "[51]\tvalid_0's l1: 0.0647226\n",
      "[52]\tvalid_0's l1: 0.0647192\n",
      "[53]\tvalid_0's l1: 0.064712\n",
      "[54]\tvalid_0's l1: 0.0647047\n",
      "[55]\tvalid_0's l1: 0.0647016\n",
      "[56]\tvalid_0's l1: 0.0646984\n",
      "[57]\tvalid_0's l1: 0.0646914\n",
      "[58]\tvalid_0's l1: 0.0646866\n",
      "[59]\tvalid_0's l1: 0.0646862\n",
      "[60]\tvalid_0's l1: 0.0646866\n",
      "[61]\tvalid_0's l1: 0.064694\n",
      "[62]\tvalid_0's l1: 0.0646967\n",
      "[63]\tvalid_0's l1: 0.0646983\n",
      "[64]\tvalid_0's l1: 0.0646998\n",
      "[65]\tvalid_0's l1: 0.0647053\n",
      "[66]\tvalid_0's l1: 0.0646993\n",
      "[67]\tvalid_0's l1: 0.0646947\n",
      "[68]\tvalid_0's l1: 0.0646946\n",
      "[69]\tvalid_0's l1: 0.0646925\n",
      "[70]\tvalid_0's l1: 0.064699\n",
      "[71]\tvalid_0's l1: 0.064699\n",
      "[72]\tvalid_0's l1: 0.0646937\n",
      "[73]\tvalid_0's l1: 0.0646931\n",
      "[74]\tvalid_0's l1: 0.0646948\n",
      "[75]\tvalid_0's l1: 0.0646916\n",
      "[76]\tvalid_0's l1: 0.0646871\n",
      "[77]\tvalid_0's l1: 0.0646812\n",
      "[78]\tvalid_0's l1: 0.0646831\n",
      "[79]\tvalid_0's l1: 0.0646819\n",
      "[80]\tvalid_0's l1: 0.0646828\n",
      "[81]\tvalid_0's l1: 0.0646822\n",
      "[82]\tvalid_0's l1: 0.0646772\n",
      "[83]\tvalid_0's l1: 0.0646727\n",
      "[84]\tvalid_0's l1: 0.0646698\n",
      "[85]\tvalid_0's l1: 0.0646619\n",
      "[86]\tvalid_0's l1: 0.0646575\n",
      "[87]\tvalid_0's l1: 0.0646627\n",
      "[88]\tvalid_0's l1: 0.0646608\n",
      "[89]\tvalid_0's l1: 0.0646585\n",
      "[90]\tvalid_0's l1: 0.0646608\n",
      "[91]\tvalid_0's l1: 0.064657\n",
      "[92]\tvalid_0's l1: 0.0646565\n",
      "[93]\tvalid_0's l1: 0.0646557\n",
      "[94]\tvalid_0's l1: 0.0646542\n",
      "[95]\tvalid_0's l1: 0.0646586\n",
      "[96]\tvalid_0's l1: 0.0646554\n",
      "[97]\tvalid_0's l1: 0.0646575\n",
      "[98]\tvalid_0's l1: 0.0646583\n",
      "[99]\tvalid_0's l1: 0.064657\n",
      "[100]\tvalid_0's l1: 0.064658\n",
      "[101]\tvalid_0's l1: 0.0646587\n",
      "[102]\tvalid_0's l1: 0.0646617\n",
      "[103]\tvalid_0's l1: 0.0646627\n",
      "[104]\tvalid_0's l1: 0.0646668\n",
      "[105]\tvalid_0's l1: 0.064665\n",
      "[106]\tvalid_0's l1: 0.0646647\n",
      "[107]\tvalid_0's l1: 0.0646675\n",
      "[108]\tvalid_0's l1: 0.0646688\n",
      "[109]\tvalid_0's l1: 0.0646687\n",
      "[110]\tvalid_0's l1: 0.0646694\n",
      "[111]\tvalid_0's l1: 0.0646718\n",
      "[112]\tvalid_0's l1: 0.0646734\n",
      "[113]\tvalid_0's l1: 0.0646685\n",
      "[114]\tvalid_0's l1: 0.0646704\n",
      "[115]\tvalid_0's l1: 0.0646692\n",
      "[116]\tvalid_0's l1: 0.0646669\n",
      "[117]\tvalid_0's l1: 0.0646675\n",
      "[118]\tvalid_0's l1: 0.0646649\n",
      "[119]\tvalid_0's l1: 0.0646659\n",
      "[120]\tvalid_0's l1: 0.0646688\n",
      "[121]\tvalid_0's l1: 0.0646701\n",
      "[122]\tvalid_0's l1: 0.0646695\n",
      "[123]\tvalid_0's l1: 0.0646659\n",
      "[124]\tvalid_0's l1: 0.0646669\n",
      "[125]\tvalid_0's l1: 0.0646683\n",
      "[126]\tvalid_0's l1: 0.064662\n",
      "[127]\tvalid_0's l1: 0.0646675\n",
      "[128]\tvalid_0's l1: 0.0646682\n",
      "[129]\tvalid_0's l1: 0.0646672\n",
      "[130]\tvalid_0's l1: 0.064666\n",
      "[131]\tvalid_0's l1: 0.0646659\n",
      "[132]\tvalid_0's l1: 0.0646655\n",
      "[133]\tvalid_0's l1: 0.0646694\n",
      "[134]\tvalid_0's l1: 0.0646646\n",
      "[135]\tvalid_0's l1: 0.0646659\n",
      "[136]\tvalid_0's l1: 0.064669\n",
      "[137]\tvalid_0's l1: 0.0646705\n",
      "[138]\tvalid_0's l1: 0.0646713\n",
      "[139]\tvalid_0's l1: 0.0646701\n",
      "[140]\tvalid_0's l1: 0.0646735\n",
      "[141]\tvalid_0's l1: 0.0646706\n",
      "[142]\tvalid_0's l1: 0.0646721\n",
      "[143]\tvalid_0's l1: 0.064675\n",
      "[144]\tvalid_0's l1: 0.0646675\n",
      "[145]\tvalid_0's l1: 0.0646724\n",
      "[146]\tvalid_0's l1: 0.0646721\n",
      "[147]\tvalid_0's l1: 0.0646745\n",
      "[148]\tvalid_0's l1: 0.0646765\n",
      "[149]\tvalid_0's l1: 0.0646746\n",
      "[150]\tvalid_0's l1: 0.0646738\n",
      "[151]\tvalid_0's l1: 0.0646728\n",
      "[152]\tvalid_0's l1: 0.0646753\n",
      "[153]\tvalid_0's l1: 0.0646765\n",
      "[154]\tvalid_0's l1: 0.0646763\n",
      "[155]\tvalid_0's l1: 0.0646801\n",
      "[156]\tvalid_0's l1: 0.0646808\n",
      "[157]\tvalid_0's l1: 0.0646812\n",
      "[158]\tvalid_0's l1: 0.0646858\n",
      "[159]\tvalid_0's l1: 0.0646875\n",
      "[160]\tvalid_0's l1: 0.064689\n",
      "[161]\tvalid_0's l1: 0.0646883\n",
      "[162]\tvalid_0's l1: 0.0646851\n",
      "[163]\tvalid_0's l1: 0.0646857\n",
      "[164]\tvalid_0's l1: 0.0646847\n",
      "[165]\tvalid_0's l1: 0.0646841\n",
      "[166]\tvalid_0's l1: 0.064684\n",
      "[167]\tvalid_0's l1: 0.0646871\n",
      "[168]\tvalid_0's l1: 0.0646936\n",
      "[169]\tvalid_0's l1: 0.0646974\n",
      "[170]\tvalid_0's l1: 0.0647008\n",
      "[171]\tvalid_0's l1: 0.0646986\n",
      "[172]\tvalid_0's l1: 0.0646998\n",
      "[173]\tvalid_0's l1: 0.0647039\n",
      "[174]\tvalid_0's l1: 0.0647058\n",
      "[175]\tvalid_0's l1: 0.0647012\n",
      "[176]\tvalid_0's l1: 0.0647038\n",
      "[177]\tvalid_0's l1: 0.0647055\n",
      "[178]\tvalid_0's l1: 0.0647082\n",
      "[179]\tvalid_0's l1: 0.0647085\n",
      "[180]\tvalid_0's l1: 0.0647068\n",
      "[181]\tvalid_0's l1: 0.0647092\n",
      "[182]\tvalid_0's l1: 0.0647049\n",
      "[183]\tvalid_0's l1: 0.0647043\n",
      "[184]\tvalid_0's l1: 0.0647011\n",
      "[185]\tvalid_0's l1: 0.0647035\n",
      "[186]\tvalid_0's l1: 0.0647013\n",
      "[187]\tvalid_0's l1: 0.0646977\n",
      "[188]\tvalid_0's l1: 0.0646968\n",
      "[189]\tvalid_0's l1: 0.0646983\n",
      "[190]\tvalid_0's l1: 0.0647016\n",
      "[191]\tvalid_0's l1: 0.0647067\n",
      "[192]\tvalid_0's l1: 0.0647093\n",
      "[193]\tvalid_0's l1: 0.0647107\n",
      "[194]\tvalid_0's l1: 0.0647137\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 0.0646542\n",
      "[1]\tvalid_0's l1: 0.0660342\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0659976\n",
      "[3]\tvalid_0's l1: 0.0659661\n",
      "[4]\tvalid_0's l1: 0.065929\n",
      "[5]\tvalid_0's l1: 0.0658961\n",
      "[6]\tvalid_0's l1: 0.0658657\n",
      "[7]\tvalid_0's l1: 0.0658398\n",
      "[8]\tvalid_0's l1: 0.0658109\n",
      "[9]\tvalid_0's l1: 0.0657863\n",
      "[10]\tvalid_0's l1: 0.0657673\n",
      "[11]\tvalid_0's l1: 0.0657379\n",
      "[12]\tvalid_0's l1: 0.0657167\n",
      "[13]\tvalid_0's l1: 0.0656952\n",
      "[14]\tvalid_0's l1: 0.065674\n",
      "[15]\tvalid_0's l1: 0.0656625\n",
      "[16]\tvalid_0's l1: 0.0656409\n",
      "[17]\tvalid_0's l1: 0.0656228\n",
      "[18]\tvalid_0's l1: 0.0656107\n",
      "[19]\tvalid_0's l1: 0.0655992\n",
      "[20]\tvalid_0's l1: 0.0655854\n",
      "[21]\tvalid_0's l1: 0.0655713\n",
      "[22]\tvalid_0's l1: 0.065559\n",
      "[23]\tvalid_0's l1: 0.0655366\n",
      "[24]\tvalid_0's l1: 0.0655199\n",
      "[25]\tvalid_0's l1: 0.0654998\n",
      "[26]\tvalid_0's l1: 0.0654837\n",
      "[27]\tvalid_0's l1: 0.0654717\n",
      "[28]\tvalid_0's l1: 0.0654609\n",
      "[29]\tvalid_0's l1: 0.0654453\n",
      "[30]\tvalid_0's l1: 0.0654326\n",
      "[31]\tvalid_0's l1: 0.0654199\n",
      "[32]\tvalid_0's l1: 0.06541\n",
      "[33]\tvalid_0's l1: 0.0653935\n",
      "[34]\tvalid_0's l1: 0.0653822\n",
      "[35]\tvalid_0's l1: 0.0653718\n",
      "[36]\tvalid_0's l1: 0.0653636\n",
      "[37]\tvalid_0's l1: 0.0653566\n",
      "[38]\tvalid_0's l1: 0.0653487\n",
      "[39]\tvalid_0's l1: 0.0653363\n",
      "[40]\tvalid_0's l1: 0.0653341\n",
      "[41]\tvalid_0's l1: 0.0653231\n",
      "[42]\tvalid_0's l1: 0.0653163\n",
      "[43]\tvalid_0's l1: 0.0653102\n",
      "[44]\tvalid_0's l1: 0.0653061\n",
      "[45]\tvalid_0's l1: 0.0653003\n",
      "[46]\tvalid_0's l1: 0.0652928\n",
      "[47]\tvalid_0's l1: 0.0652831\n",
      "[48]\tvalid_0's l1: 0.0652797\n",
      "[49]\tvalid_0's l1: 0.0652761\n",
      "[50]\tvalid_0's l1: 0.06527\n",
      "[51]\tvalid_0's l1: 0.0652666\n",
      "[52]\tvalid_0's l1: 0.0652671\n",
      "[53]\tvalid_0's l1: 0.0652654\n",
      "[54]\tvalid_0's l1: 0.0652626\n",
      "[55]\tvalid_0's l1: 0.0652588\n",
      "[56]\tvalid_0's l1: 0.0652561\n",
      "[57]\tvalid_0's l1: 0.0652502\n",
      "[58]\tvalid_0's l1: 0.0652458\n",
      "[59]\tvalid_0's l1: 0.0652406\n",
      "[60]\tvalid_0's l1: 0.0652372\n",
      "[61]\tvalid_0's l1: 0.0652297\n",
      "[62]\tvalid_0's l1: 0.0652289\n",
      "[63]\tvalid_0's l1: 0.0652218\n",
      "[64]\tvalid_0's l1: 0.0652201\n",
      "[65]\tvalid_0's l1: 0.0652247\n",
      "[66]\tvalid_0's l1: 0.0652219\n",
      "[67]\tvalid_0's l1: 0.0652213\n",
      "[68]\tvalid_0's l1: 0.0652176\n",
      "[69]\tvalid_0's l1: 0.0652167\n",
      "[70]\tvalid_0's l1: 0.0652155\n",
      "[71]\tvalid_0's l1: 0.0652091\n",
      "[72]\tvalid_0's l1: 0.0652081\n",
      "[73]\tvalid_0's l1: 0.0652055\n",
      "[74]\tvalid_0's l1: 0.0652023\n",
      "[75]\tvalid_0's l1: 0.0651992\n",
      "[76]\tvalid_0's l1: 0.0651985\n",
      "[77]\tvalid_0's l1: 0.0651955\n",
      "[78]\tvalid_0's l1: 0.0651954\n",
      "[79]\tvalid_0's l1: 0.065196\n",
      "[80]\tvalid_0's l1: 0.065198\n",
      "[81]\tvalid_0's l1: 0.0652006\n",
      "[82]\tvalid_0's l1: 0.0651966\n",
      "[83]\tvalid_0's l1: 0.0651959\n",
      "[84]\tvalid_0's l1: 0.0651943\n",
      "[85]\tvalid_0's l1: 0.0651917\n",
      "[86]\tvalid_0's l1: 0.0651878\n",
      "[87]\tvalid_0's l1: 0.065184\n",
      "[88]\tvalid_0's l1: 0.0651848\n",
      "[89]\tvalid_0's l1: 0.0651854\n",
      "[90]\tvalid_0's l1: 0.0651815\n",
      "[91]\tvalid_0's l1: 0.0651798\n",
      "[92]\tvalid_0's l1: 0.0651793\n",
      "[93]\tvalid_0's l1: 0.0651789\n",
      "[94]\tvalid_0's l1: 0.065182\n",
      "[95]\tvalid_0's l1: 0.0651786\n",
      "[96]\tvalid_0's l1: 0.0651792\n",
      "[97]\tvalid_0's l1: 0.0651758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98]\tvalid_0's l1: 0.0651741\n",
      "[99]\tvalid_0's l1: 0.0651752\n",
      "[100]\tvalid_0's l1: 0.0651769\n",
      "[101]\tvalid_0's l1: 0.0651729\n",
      "[102]\tvalid_0's l1: 0.065175\n",
      "[103]\tvalid_0's l1: 0.0651779\n",
      "[104]\tvalid_0's l1: 0.0651845\n",
      "[105]\tvalid_0's l1: 0.065185\n",
      "[106]\tvalid_0's l1: 0.0651867\n",
      "[107]\tvalid_0's l1: 0.0651926\n",
      "[108]\tvalid_0's l1: 0.0651912\n",
      "[109]\tvalid_0's l1: 0.0651909\n",
      "[110]\tvalid_0's l1: 0.065189\n",
      "[111]\tvalid_0's l1: 0.0651855\n",
      "[112]\tvalid_0's l1: 0.0651866\n",
      "[113]\tvalid_0's l1: 0.0651903\n",
      "[114]\tvalid_0's l1: 0.0651865\n",
      "[115]\tvalid_0's l1: 0.0651901\n",
      "[116]\tvalid_0's l1: 0.0651889\n",
      "[117]\tvalid_0's l1: 0.0651927\n",
      "[118]\tvalid_0's l1: 0.0651933\n",
      "[119]\tvalid_0's l1: 0.0651923\n",
      "[120]\tvalid_0's l1: 0.0651934\n",
      "[121]\tvalid_0's l1: 0.0651881\n",
      "[122]\tvalid_0's l1: 0.0651816\n",
      "[123]\tvalid_0's l1: 0.0651822\n",
      "[124]\tvalid_0's l1: 0.0651841\n",
      "[125]\tvalid_0's l1: 0.0651846\n",
      "[126]\tvalid_0's l1: 0.0651853\n",
      "[127]\tvalid_0's l1: 0.0651853\n",
      "[128]\tvalid_0's l1: 0.0651865\n",
      "[129]\tvalid_0's l1: 0.0651863\n",
      "[130]\tvalid_0's l1: 0.0651922\n",
      "[131]\tvalid_0's l1: 0.0651936\n",
      "[132]\tvalid_0's l1: 0.0651916\n",
      "[133]\tvalid_0's l1: 0.0651937\n",
      "[134]\tvalid_0's l1: 0.0651968\n",
      "[135]\tvalid_0's l1: 0.0652025\n",
      "[136]\tvalid_0's l1: 0.0652004\n",
      "[137]\tvalid_0's l1: 0.065201\n",
      "[138]\tvalid_0's l1: 0.065208\n",
      "[139]\tvalid_0's l1: 0.0652072\n",
      "[140]\tvalid_0's l1: 0.0652039\n",
      "[141]\tvalid_0's l1: 0.0652062\n",
      "[142]\tvalid_0's l1: 0.0652008\n",
      "[143]\tvalid_0's l1: 0.0652011\n",
      "[144]\tvalid_0's l1: 0.0652029\n",
      "[145]\tvalid_0's l1: 0.0652036\n",
      "[146]\tvalid_0's l1: 0.0652043\n",
      "[147]\tvalid_0's l1: 0.0652038\n",
      "[148]\tvalid_0's l1: 0.0652021\n",
      "[149]\tvalid_0's l1: 0.0652007\n",
      "[150]\tvalid_0's l1: 0.0651968\n",
      "[151]\tvalid_0's l1: 0.0651966\n",
      "[152]\tvalid_0's l1: 0.065198\n",
      "[153]\tvalid_0's l1: 0.0652\n",
      "[154]\tvalid_0's l1: 0.0652045\n",
      "[155]\tvalid_0's l1: 0.065207\n",
      "[156]\tvalid_0's l1: 0.0652096\n",
      "[157]\tvalid_0's l1: 0.0652102\n",
      "[158]\tvalid_0's l1: 0.0652173\n",
      "[159]\tvalid_0's l1: 0.0652174\n",
      "[160]\tvalid_0's l1: 0.0652175\n",
      "[161]\tvalid_0's l1: 0.0652209\n",
      "[162]\tvalid_0's l1: 0.0652214\n",
      "[163]\tvalid_0's l1: 0.0652227\n",
      "[164]\tvalid_0's l1: 0.0652225\n",
      "[165]\tvalid_0's l1: 0.0652289\n",
      "[166]\tvalid_0's l1: 0.0652285\n",
      "[167]\tvalid_0's l1: 0.0652289\n",
      "[168]\tvalid_0's l1: 0.0652278\n",
      "[169]\tvalid_0's l1: 0.065228\n",
      "[170]\tvalid_0's l1: 0.0652312\n",
      "[171]\tvalid_0's l1: 0.0652327\n",
      "[172]\tvalid_0's l1: 0.0652352\n",
      "[173]\tvalid_0's l1: 0.0652361\n",
      "[174]\tvalid_0's l1: 0.0652411\n",
      "[175]\tvalid_0's l1: 0.0652442\n",
      "[176]\tvalid_0's l1: 0.0652439\n",
      "[177]\tvalid_0's l1: 0.0652426\n",
      "[178]\tvalid_0's l1: 0.0652413\n",
      "[179]\tvalid_0's l1: 0.0652378\n",
      "[180]\tvalid_0's l1: 0.0652407\n",
      "[181]\tvalid_0's l1: 0.0652436\n",
      "[182]\tvalid_0's l1: 0.0652483\n",
      "[183]\tvalid_0's l1: 0.0652512\n",
      "[184]\tvalid_0's l1: 0.0652529\n",
      "[185]\tvalid_0's l1: 0.0652537\n",
      "[186]\tvalid_0's l1: 0.065251\n",
      "[187]\tvalid_0's l1: 0.0652486\n",
      "[188]\tvalid_0's l1: 0.0652535\n",
      "[189]\tvalid_0's l1: 0.0652549\n",
      "[190]\tvalid_0's l1: 0.0652541\n",
      "[191]\tvalid_0's l1: 0.0652527\n",
      "[192]\tvalid_0's l1: 0.0652529\n",
      "[193]\tvalid_0's l1: 0.065254\n",
      "[194]\tvalid_0's l1: 0.0652557\n",
      "[195]\tvalid_0's l1: 0.0652547\n",
      "[196]\tvalid_0's l1: 0.0652559\n",
      "[197]\tvalid_0's l1: 0.0652553\n",
      "[198]\tvalid_0's l1: 0.0652588\n",
      "[199]\tvalid_0's l1: 0.0652565\n",
      "[200]\tvalid_0's l1: 0.0652591\n",
      "[201]\tvalid_0's l1: 0.0652585\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's l1: 0.0651729\n",
      "[1]\tvalid_0's l1: 0.0660624\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0660271\n",
      "[3]\tvalid_0's l1: 0.0660047\n",
      "[4]\tvalid_0's l1: 0.0659813\n",
      "[5]\tvalid_0's l1: 0.0659588\n",
      "[6]\tvalid_0's l1: 0.0659334\n",
      "[7]\tvalid_0's l1: 0.0659013\n",
      "[8]\tvalid_0's l1: 0.0658775\n",
      "[9]\tvalid_0's l1: 0.0658584\n",
      "[10]\tvalid_0's l1: 0.0658343\n",
      "[11]\tvalid_0's l1: 0.0658129\n",
      "[12]\tvalid_0's l1: 0.0657893\n",
      "[13]\tvalid_0's l1: 0.065773\n",
      "[14]\tvalid_0's l1: 0.0657544\n",
      "[15]\tvalid_0's l1: 0.0657405\n",
      "[16]\tvalid_0's l1: 0.0657298\n",
      "[17]\tvalid_0's l1: 0.0657163\n",
      "[18]\tvalid_0's l1: 0.0657038\n",
      "[19]\tvalid_0's l1: 0.0656952\n",
      "[20]\tvalid_0's l1: 0.0656786\n",
      "[21]\tvalid_0's l1: 0.0656657\n",
      "[22]\tvalid_0's l1: 0.0656494\n",
      "[23]\tvalid_0's l1: 0.065639\n",
      "[24]\tvalid_0's l1: 0.0656204\n",
      "[25]\tvalid_0's l1: 0.065613\n",
      "[26]\tvalid_0's l1: 0.0656032\n",
      "[27]\tvalid_0's l1: 0.0655975\n",
      "[28]\tvalid_0's l1: 0.0655896\n",
      "[29]\tvalid_0's l1: 0.0655794\n",
      "[30]\tvalid_0's l1: 0.0655694\n",
      "[31]\tvalid_0's l1: 0.0655604\n",
      "[32]\tvalid_0's l1: 0.0655552\n",
      "[33]\tvalid_0's l1: 0.0655503\n",
      "[34]\tvalid_0's l1: 0.0655449\n",
      "[35]\tvalid_0's l1: 0.065543\n",
      "[36]\tvalid_0's l1: 0.0655308\n",
      "[37]\tvalid_0's l1: 0.0655255\n",
      "[38]\tvalid_0's l1: 0.0655208\n",
      "[39]\tvalid_0's l1: 0.0655168\n",
      "[40]\tvalid_0's l1: 0.0655088\n",
      "[41]\tvalid_0's l1: 0.0655037\n",
      "[42]\tvalid_0's l1: 0.0654945\n",
      "[43]\tvalid_0's l1: 0.0654895\n",
      "[44]\tvalid_0's l1: 0.0654772\n",
      "[45]\tvalid_0's l1: 0.0654712\n",
      "[46]\tvalid_0's l1: 0.0654636\n",
      "[47]\tvalid_0's l1: 0.0654594\n",
      "[48]\tvalid_0's l1: 0.0654529\n",
      "[49]\tvalid_0's l1: 0.0654464\n",
      "[50]\tvalid_0's l1: 0.0654377\n",
      "[51]\tvalid_0's l1: 0.0654313\n",
      "[52]\tvalid_0's l1: 0.0654283\n",
      "[53]\tvalid_0's l1: 0.0654221\n",
      "[54]\tvalid_0's l1: 0.0654172\n",
      "[55]\tvalid_0's l1: 0.0654163\n",
      "[56]\tvalid_0's l1: 0.0654171\n",
      "[57]\tvalid_0's l1: 0.0654099\n",
      "[58]\tvalid_0's l1: 0.0654034\n",
      "[59]\tvalid_0's l1: 0.0653983\n",
      "[60]\tvalid_0's l1: 0.0653979\n",
      "[61]\tvalid_0's l1: 0.0653949\n",
      "[62]\tvalid_0's l1: 0.0653881\n",
      "[63]\tvalid_0's l1: 0.0653888\n",
      "[64]\tvalid_0's l1: 0.0653883\n",
      "[65]\tvalid_0's l1: 0.065387\n",
      "[66]\tvalid_0's l1: 0.0653864\n",
      "[67]\tvalid_0's l1: 0.065386\n",
      "[68]\tvalid_0's l1: 0.0653779\n",
      "[69]\tvalid_0's l1: 0.0653769\n",
      "[70]\tvalid_0's l1: 0.0653716\n",
      "[71]\tvalid_0's l1: 0.0653686\n",
      "[72]\tvalid_0's l1: 0.0653651\n",
      "[73]\tvalid_0's l1: 0.0653615\n",
      "[74]\tvalid_0's l1: 0.0653514\n",
      "[75]\tvalid_0's l1: 0.0653533\n",
      "[76]\tvalid_0's l1: 0.0653507\n",
      "[77]\tvalid_0's l1: 0.0653495\n",
      "[78]\tvalid_0's l1: 0.0653504\n",
      "[79]\tvalid_0's l1: 0.0653557\n",
      "[80]\tvalid_0's l1: 0.0653608\n",
      "[81]\tvalid_0's l1: 0.0653591\n",
      "[82]\tvalid_0's l1: 0.0653482\n",
      "[83]\tvalid_0's l1: 0.0653475\n",
      "[84]\tvalid_0's l1: 0.0653444\n",
      "[85]\tvalid_0's l1: 0.0653449\n",
      "[86]\tvalid_0's l1: 0.0653436\n",
      "[87]\tvalid_0's l1: 0.0653466\n",
      "[88]\tvalid_0's l1: 0.0653473\n",
      "[89]\tvalid_0's l1: 0.0653462\n",
      "[90]\tvalid_0's l1: 0.0653422\n",
      "[91]\tvalid_0's l1: 0.0653353\n",
      "[92]\tvalid_0's l1: 0.0653332\n",
      "[93]\tvalid_0's l1: 0.0653319\n",
      "[94]\tvalid_0's l1: 0.0653302\n",
      "[95]\tvalid_0's l1: 0.0653273\n",
      "[96]\tvalid_0's l1: 0.0653226\n",
      "[97]\tvalid_0's l1: 0.0653209\n",
      "[98]\tvalid_0's l1: 0.0653203\n",
      "[99]\tvalid_0's l1: 0.0653146\n",
      "[100]\tvalid_0's l1: 0.0653123\n",
      "[101]\tvalid_0's l1: 0.0653048\n",
      "[102]\tvalid_0's l1: 0.0653046\n",
      "[103]\tvalid_0's l1: 0.0653016\n",
      "[104]\tvalid_0's l1: 0.0653018\n",
      "[105]\tvalid_0's l1: 0.065301\n",
      "[106]\tvalid_0's l1: 0.0652998\n",
      "[107]\tvalid_0's l1: 0.0652986\n",
      "[108]\tvalid_0's l1: 0.065302\n",
      "[109]\tvalid_0's l1: 0.0652988\n",
      "[110]\tvalid_0's l1: 0.0653006\n",
      "[111]\tvalid_0's l1: 0.0653059\n",
      "[112]\tvalid_0's l1: 0.0653063\n",
      "[113]\tvalid_0's l1: 0.0653081\n",
      "[114]\tvalid_0's l1: 0.0653101\n",
      "[115]\tvalid_0's l1: 0.0653122\n",
      "[116]\tvalid_0's l1: 0.0653095\n",
      "[117]\tvalid_0's l1: 0.065306\n",
      "[118]\tvalid_0's l1: 0.0653035\n",
      "[119]\tvalid_0's l1: 0.0653019\n",
      "[120]\tvalid_0's l1: 0.0652951\n",
      "[121]\tvalid_0's l1: 0.0652946\n",
      "[122]\tvalid_0's l1: 0.0652982\n",
      "[123]\tvalid_0's l1: 0.0653011\n",
      "[124]\tvalid_0's l1: 0.0653035\n",
      "[125]\tvalid_0's l1: 0.0652995\n",
      "[126]\tvalid_0's l1: 0.0653029\n",
      "[127]\tvalid_0's l1: 0.0653007\n",
      "[128]\tvalid_0's l1: 0.0653\n",
      "[129]\tvalid_0's l1: 0.0653004\n",
      "[130]\tvalid_0's l1: 0.065296\n",
      "[131]\tvalid_0's l1: 0.0652946\n",
      "[132]\tvalid_0's l1: 0.0652917\n",
      "[133]\tvalid_0's l1: 0.0652937\n",
      "[134]\tvalid_0's l1: 0.0652959\n",
      "[135]\tvalid_0's l1: 0.0652974\n",
      "[136]\tvalid_0's l1: 0.0652977\n",
      "[137]\tvalid_0's l1: 0.0652984\n",
      "[138]\tvalid_0's l1: 0.0653038\n",
      "[139]\tvalid_0's l1: 0.0653063\n",
      "[140]\tvalid_0's l1: 0.0652998\n",
      "[141]\tvalid_0's l1: 0.0653003\n",
      "[142]\tvalid_0's l1: 0.0653007\n",
      "[143]\tvalid_0's l1: 0.0653004\n",
      "[144]\tvalid_0's l1: 0.0653051\n",
      "[145]\tvalid_0's l1: 0.0653087\n",
      "[146]\tvalid_0's l1: 0.0653079\n",
      "[147]\tvalid_0's l1: 0.0653095\n",
      "[148]\tvalid_0's l1: 0.0653084\n",
      "[149]\tvalid_0's l1: 0.0653065\n",
      "[150]\tvalid_0's l1: 0.0653057\n",
      "[151]\tvalid_0's l1: 0.0653044\n",
      "[152]\tvalid_0's l1: 0.065307\n",
      "[153]\tvalid_0's l1: 0.065305\n",
      "[154]\tvalid_0's l1: 0.0653057\n",
      "[155]\tvalid_0's l1: 0.0653064\n",
      "[156]\tvalid_0's l1: 0.0653065\n",
      "[157]\tvalid_0's l1: 0.0653046\n",
      "[158]\tvalid_0's l1: 0.0653056\n",
      "[159]\tvalid_0's l1: 0.065304\n",
      "[160]\tvalid_0's l1: 0.0653083\n",
      "[161]\tvalid_0's l1: 0.0653082\n",
      "[162]\tvalid_0's l1: 0.0653129\n",
      "[163]\tvalid_0's l1: 0.0653176\n",
      "[164]\tvalid_0's l1: 0.0653223\n",
      "[165]\tvalid_0's l1: 0.0653243\n",
      "[166]\tvalid_0's l1: 0.0653233\n",
      "[167]\tvalid_0's l1: 0.0653233\n",
      "[168]\tvalid_0's l1: 0.0653265\n",
      "[169]\tvalid_0's l1: 0.0653314\n",
      "[170]\tvalid_0's l1: 0.0653276\n",
      "[171]\tvalid_0's l1: 0.065328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172]\tvalid_0's l1: 0.0653299\n",
      "[173]\tvalid_0's l1: 0.065332\n",
      "[174]\tvalid_0's l1: 0.0653363\n",
      "[175]\tvalid_0's l1: 0.0653418\n",
      "[176]\tvalid_0's l1: 0.0653416\n",
      "[177]\tvalid_0's l1: 0.0653394\n",
      "[178]\tvalid_0's l1: 0.0653371\n",
      "[179]\tvalid_0's l1: 0.0653335\n",
      "[180]\tvalid_0's l1: 0.0653342\n",
      "[181]\tvalid_0's l1: 0.0653364\n",
      "[182]\tvalid_0's l1: 0.0653418\n",
      "[183]\tvalid_0's l1: 0.0653424\n",
      "[184]\tvalid_0's l1: 0.0653439\n",
      "[185]\tvalid_0's l1: 0.0653495\n",
      "[186]\tvalid_0's l1: 0.0653519\n",
      "[187]\tvalid_0's l1: 0.0653561\n",
      "[188]\tvalid_0's l1: 0.0653565\n",
      "[189]\tvalid_0's l1: 0.0653578\n",
      "[190]\tvalid_0's l1: 0.0653588\n",
      "[191]\tvalid_0's l1: 0.0653579\n",
      "[192]\tvalid_0's l1: 0.0653576\n",
      "[193]\tvalid_0's l1: 0.0653595\n",
      "[194]\tvalid_0's l1: 0.0653561\n",
      "[195]\tvalid_0's l1: 0.0653528\n",
      "[196]\tvalid_0's l1: 0.0653548\n",
      "[197]\tvalid_0's l1: 0.0653624\n",
      "[198]\tvalid_0's l1: 0.0653637\n",
      "[199]\tvalid_0's l1: 0.0653636\n",
      "[200]\tvalid_0's l1: 0.0653664\n",
      "[201]\tvalid_0's l1: 0.0653711\n",
      "[202]\tvalid_0's l1: 0.0653707\n",
      "[203]\tvalid_0's l1: 0.06537\n",
      "[204]\tvalid_0's l1: 0.0653715\n",
      "[205]\tvalid_0's l1: 0.0653759\n",
      "[206]\tvalid_0's l1: 0.0653743\n",
      "[207]\tvalid_0's l1: 0.0653774\n",
      "[208]\tvalid_0's l1: 0.0653778\n",
      "[209]\tvalid_0's l1: 0.065375\n",
      "[210]\tvalid_0's l1: 0.0653725\n",
      "[211]\tvalid_0's l1: 0.0653722\n",
      "[212]\tvalid_0's l1: 0.0653677\n",
      "[213]\tvalid_0's l1: 0.0653676\n",
      "[214]\tvalid_0's l1: 0.0653702\n",
      "[215]\tvalid_0's l1: 0.0653702\n",
      "[216]\tvalid_0's l1: 0.0653683\n",
      "[217]\tvalid_0's l1: 0.0653726\n",
      "[218]\tvalid_0's l1: 0.0653752\n",
      "[219]\tvalid_0's l1: 0.0653737\n",
      "[220]\tvalid_0's l1: 0.0653754\n",
      "[221]\tvalid_0's l1: 0.0653736\n",
      "[222]\tvalid_0's l1: 0.0653749\n",
      "[223]\tvalid_0's l1: 0.065374\n",
      "[224]\tvalid_0's l1: 0.0653742\n",
      "[225]\tvalid_0's l1: 0.0653736\n",
      "[226]\tvalid_0's l1: 0.0653782\n",
      "[227]\tvalid_0's l1: 0.0653791\n",
      "[228]\tvalid_0's l1: 0.0653852\n",
      "[229]\tvalid_0's l1: 0.0653821\n",
      "[230]\tvalid_0's l1: 0.0653824\n",
      "[231]\tvalid_0's l1: 0.0653816\n",
      "[232]\tvalid_0's l1: 0.0653776\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's l1: 0.0652917\n",
      "[1]\tvalid_0's l1: 0.0659017\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[2]\tvalid_0's l1: 0.0658676\n",
      "[3]\tvalid_0's l1: 0.0658335\n",
      "[4]\tvalid_0's l1: 0.0658065\n",
      "[5]\tvalid_0's l1: 0.0657793\n",
      "[6]\tvalid_0's l1: 0.0657486\n",
      "[7]\tvalid_0's l1: 0.0657193\n",
      "[8]\tvalid_0's l1: 0.0656841\n",
      "[9]\tvalid_0's l1: 0.065657\n",
      "[10]\tvalid_0's l1: 0.065634\n",
      "[11]\tvalid_0's l1: 0.0656137\n",
      "[12]\tvalid_0's l1: 0.0655881\n",
      "[13]\tvalid_0's l1: 0.0655767\n",
      "[14]\tvalid_0's l1: 0.0655569\n",
      "[15]\tvalid_0's l1: 0.0655403\n",
      "[16]\tvalid_0's l1: 0.0655276\n",
      "[17]\tvalid_0's l1: 0.0655153\n",
      "[18]\tvalid_0's l1: 0.0655066\n",
      "[19]\tvalid_0's l1: 0.0655013\n",
      "[20]\tvalid_0's l1: 0.0655006\n",
      "[21]\tvalid_0's l1: 0.0654873\n",
      "[22]\tvalid_0's l1: 0.0654767\n",
      "[23]\tvalid_0's l1: 0.0654642\n",
      "[24]\tvalid_0's l1: 0.0654577\n",
      "[25]\tvalid_0's l1: 0.0654501\n",
      "[26]\tvalid_0's l1: 0.0654392\n",
      "[27]\tvalid_0's l1: 0.0654298\n",
      "[28]\tvalid_0's l1: 0.0654208\n",
      "[29]\tvalid_0's l1: 0.06541\n",
      "[30]\tvalid_0's l1: 0.0654038\n",
      "[31]\tvalid_0's l1: 0.0653945\n",
      "[32]\tvalid_0's l1: 0.0653888\n",
      "[33]\tvalid_0's l1: 0.0653817\n",
      "[34]\tvalid_0's l1: 0.0653759\n",
      "[35]\tvalid_0's l1: 0.065381\n",
      "[36]\tvalid_0's l1: 0.0653805\n",
      "[37]\tvalid_0's l1: 0.0653808\n",
      "[38]\tvalid_0's l1: 0.0653813\n",
      "[39]\tvalid_0's l1: 0.0653822\n",
      "[40]\tvalid_0's l1: 0.0653809\n",
      "[41]\tvalid_0's l1: 0.0653785\n",
      "[42]\tvalid_0's l1: 0.0653742\n",
      "[43]\tvalid_0's l1: 0.0653673\n",
      "[44]\tvalid_0's l1: 0.0653607\n",
      "[45]\tvalid_0's l1: 0.0653632\n",
      "[46]\tvalid_0's l1: 0.0653575\n",
      "[47]\tvalid_0's l1: 0.0653522\n",
      "[48]\tvalid_0's l1: 0.0653514\n",
      "[49]\tvalid_0's l1: 0.0653457\n",
      "[50]\tvalid_0's l1: 0.0653433\n",
      "[51]\tvalid_0's l1: 0.065344\n",
      "[52]\tvalid_0's l1: 0.065345\n",
      "[53]\tvalid_0's l1: 0.0653464\n",
      "[54]\tvalid_0's l1: 0.0653465\n",
      "[55]\tvalid_0's l1: 0.0653436\n",
      "[56]\tvalid_0's l1: 0.065342\n",
      "[57]\tvalid_0's l1: 0.0653443\n",
      "[58]\tvalid_0's l1: 0.0653418\n",
      "[59]\tvalid_0's l1: 0.0653419\n",
      "[60]\tvalid_0's l1: 0.0653425\n",
      "[61]\tvalid_0's l1: 0.0653448\n",
      "[62]\tvalid_0's l1: 0.0653446\n",
      "[63]\tvalid_0's l1: 0.0653498\n",
      "[64]\tvalid_0's l1: 0.0653491\n",
      "[65]\tvalid_0's l1: 0.065351\n",
      "[66]\tvalid_0's l1: 0.0653523\n",
      "[67]\tvalid_0's l1: 0.0653538\n",
      "[68]\tvalid_0's l1: 0.0653545\n",
      "[69]\tvalid_0's l1: 0.0653587\n",
      "[70]\tvalid_0's l1: 0.0653604\n",
      "[71]\tvalid_0's l1: 0.0653622\n",
      "[72]\tvalid_0's l1: 0.0653668\n",
      "[73]\tvalid_0's l1: 0.0653694\n",
      "[74]\tvalid_0's l1: 0.0653713\n",
      "[75]\tvalid_0's l1: 0.0653743\n",
      "[76]\tvalid_0's l1: 0.065379\n",
      "[77]\tvalid_0's l1: 0.0653776\n",
      "[78]\tvalid_0's l1: 0.0653853\n",
      "[79]\tvalid_0's l1: 0.0653839\n",
      "[80]\tvalid_0's l1: 0.065385\n",
      "[81]\tvalid_0's l1: 0.065385\n",
      "[82]\tvalid_0's l1: 0.065381\n",
      "[83]\tvalid_0's l1: 0.0653797\n",
      "[84]\tvalid_0's l1: 0.0653781\n",
      "[85]\tvalid_0's l1: 0.0653742\n",
      "[86]\tvalid_0's l1: 0.0653766\n",
      "[87]\tvalid_0's l1: 0.0653769\n",
      "[88]\tvalid_0's l1: 0.0653766\n",
      "[89]\tvalid_0's l1: 0.0653715\n",
      "[90]\tvalid_0's l1: 0.0653674\n",
      "[91]\tvalid_0's l1: 0.0653667\n",
      "[92]\tvalid_0's l1: 0.0653645\n",
      "[93]\tvalid_0's l1: 0.0653653\n",
      "[94]\tvalid_0's l1: 0.0653677\n",
      "[95]\tvalid_0's l1: 0.0653675\n",
      "[96]\tvalid_0's l1: 0.065369\n",
      "[97]\tvalid_0's l1: 0.0653698\n",
      "[98]\tvalid_0's l1: 0.0653706\n",
      "[99]\tvalid_0's l1: 0.0653725\n",
      "[100]\tvalid_0's l1: 0.0653752\n",
      "[101]\tvalid_0's l1: 0.0653764\n",
      "[102]\tvalid_0's l1: 0.0653751\n",
      "[103]\tvalid_0's l1: 0.0653786\n",
      "[104]\tvalid_0's l1: 0.0653817\n",
      "[105]\tvalid_0's l1: 0.0653797\n",
      "[106]\tvalid_0's l1: 0.0653799\n",
      "[107]\tvalid_0's l1: 0.0653802\n",
      "[108]\tvalid_0's l1: 0.0653773\n",
      "[109]\tvalid_0's l1: 0.0653727\n",
      "[110]\tvalid_0's l1: 0.0653691\n",
      "[111]\tvalid_0's l1: 0.0653678\n",
      "[112]\tvalid_0's l1: 0.0653708\n",
      "[113]\tvalid_0's l1: 0.065371\n",
      "[114]\tvalid_0's l1: 0.0653748\n",
      "[115]\tvalid_0's l1: 0.0653776\n",
      "[116]\tvalid_0's l1: 0.0653764\n",
      "[117]\tvalid_0's l1: 0.0653793\n",
      "[118]\tvalid_0's l1: 0.0653793\n",
      "[119]\tvalid_0's l1: 0.0653785\n",
      "[120]\tvalid_0's l1: 0.0653745\n",
      "[121]\tvalid_0's l1: 0.0653741\n",
      "[122]\tvalid_0's l1: 0.0653733\n",
      "[123]\tvalid_0's l1: 0.065376\n",
      "[124]\tvalid_0's l1: 0.0653766\n",
      "[125]\tvalid_0's l1: 0.0653769\n",
      "[126]\tvalid_0's l1: 0.0653783\n",
      "[127]\tvalid_0's l1: 0.0653772\n",
      "[128]\tvalid_0's l1: 0.0653811\n",
      "[129]\tvalid_0's l1: 0.0653806\n",
      "[130]\tvalid_0's l1: 0.065381\n",
      "[131]\tvalid_0's l1: 0.065385\n",
      "[132]\tvalid_0's l1: 0.0653858\n",
      "[133]\tvalid_0's l1: 0.0653806\n",
      "[134]\tvalid_0's l1: 0.0653829\n",
      "[135]\tvalid_0's l1: 0.0653884\n",
      "[136]\tvalid_0's l1: 0.0653872\n",
      "[137]\tvalid_0's l1: 0.0653881\n",
      "[138]\tvalid_0's l1: 0.0653885\n",
      "[139]\tvalid_0's l1: 0.0653937\n",
      "[140]\tvalid_0's l1: 0.0653925\n",
      "[141]\tvalid_0's l1: 0.0653927\n",
      "[142]\tvalid_0's l1: 0.0653946\n",
      "[143]\tvalid_0's l1: 0.0653953\n",
      "[144]\tvalid_0's l1: 0.0653982\n",
      "[145]\tvalid_0's l1: 0.0653989\n",
      "[146]\tvalid_0's l1: 0.0654028\n",
      "[147]\tvalid_0's l1: 0.0654026\n",
      "[148]\tvalid_0's l1: 0.0654027\n",
      "[149]\tvalid_0's l1: 0.0654047\n",
      "[150]\tvalid_0's l1: 0.0654096\n",
      "[151]\tvalid_0's l1: 0.0654171\n",
      "[152]\tvalid_0's l1: 0.0654218\n",
      "[153]\tvalid_0's l1: 0.0654223\n",
      "[154]\tvalid_0's l1: 0.0654217\n",
      "[155]\tvalid_0's l1: 0.065426\n",
      "[156]\tvalid_0's l1: 0.065427\n",
      "[157]\tvalid_0's l1: 0.065429\n",
      "[158]\tvalid_0's l1: 0.0654327\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l1: 0.0653418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.067578197327611431"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'mae'},\n",
    "    'num_leaves': 96,\n",
    "    'min_sum_hessian_in_leaf':20,\n",
    "    'min_hessian':10,\n",
    "    'min_data':500,\n",
    "    'max_depth': -12,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    }\n",
    "    \n",
    "kf = KFold(n_splits=10)\n",
    "average_loss = 0\n",
    "for train_index, valid_index in kf.split(x_train):\n",
    "    train_data, valid_data = x_train.loc[train_index], x_train.loc[valid_index]\n",
    "    train_label, valid_label = y_train[train_index], y_train[valid_index]\n",
    "    \n",
    "    outlier_bracket = (train_label<=0.5)&(train_label>=-0.5)\n",
    "    train_data = train_data[outlier_bracket]\n",
    "    train_label = train_label[outlier_bracket]\n",
    "    \n",
    "    d_train = lgb.Dataset(train_data, label=train_label)\n",
    "    d_valid = lgb.Dataset(valid_data, label=valid_label)\n",
    "\n",
    "    watchlist = [d_train, d_valid]\n",
    "    gbm = lgb.train(params, d_train, num_boost_round=2000, valid_sets=d_valid, early_stopping_rounds=100)\n",
    "    average_loss += gbm.eval_valid()[0][2]\n",
    "average_loss/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['importances']>0]['feature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.0723964\n",
      "Train until valid scores didn't improve in 30 rounds.\n",
      "[2]\tvalid_0's l1: 0.0723481\n",
      "[3]\tvalid_0's l1: 0.0723307\n",
      "[4]\tvalid_0's l1: 0.0722714\n",
      "[5]\tvalid_0's l1: 0.0722408\n",
      "[6]\tvalid_0's l1: 0.0721983\n",
      "[7]\tvalid_0's l1: 0.0721704\n",
      "[8]\tvalid_0's l1: 0.0721378\n",
      "[9]\tvalid_0's l1: 0.0721316\n",
      "[10]\tvalid_0's l1: 0.0720899\n",
      "[11]\tvalid_0's l1: 0.072078\n",
      "[12]\tvalid_0's l1: 0.0720767\n",
      "[13]\tvalid_0's l1: 0.0720876\n",
      "[14]\tvalid_0's l1: 0.0720609\n",
      "[15]\tvalid_0's l1: 0.0720396\n",
      "[16]\tvalid_0's l1: 0.0720316\n",
      "[17]\tvalid_0's l1: 0.07203\n",
      "[18]\tvalid_0's l1: 0.0720127\n",
      "[19]\tvalid_0's l1: 0.0719829\n",
      "[20]\tvalid_0's l1: 0.0719495\n",
      "[21]\tvalid_0's l1: 0.0719511\n",
      "[22]\tvalid_0's l1: 0.0719194\n",
      "[23]\tvalid_0's l1: 0.0719138\n",
      "[24]\tvalid_0's l1: 0.071925\n",
      "[25]\tvalid_0's l1: 0.0719307\n",
      "[26]\tvalid_0's l1: 0.0719316\n",
      "[27]\tvalid_0's l1: 0.0719207\n",
      "[28]\tvalid_0's l1: 0.071923\n",
      "[29]\tvalid_0's l1: 0.0718999\n",
      "[30]\tvalid_0's l1: 0.0719205\n",
      "[31]\tvalid_0's l1: 0.0719045\n",
      "[32]\tvalid_0's l1: 0.0718837\n",
      "[33]\tvalid_0's l1: 0.0718932\n",
      "[34]\tvalid_0's l1: 0.0718599\n",
      "[35]\tvalid_0's l1: 0.0718607\n",
      "[36]\tvalid_0's l1: 0.0718535\n",
      "[37]\tvalid_0's l1: 0.0718594\n",
      "[38]\tvalid_0's l1: 0.0718689\n",
      "[39]\tvalid_0's l1: 0.0718655\n",
      "[40]\tvalid_0's l1: 0.0718683\n",
      "[41]\tvalid_0's l1: 0.0718533\n",
      "[42]\tvalid_0's l1: 0.0718398\n",
      "[43]\tvalid_0's l1: 0.0718633\n",
      "[44]\tvalid_0's l1: 0.0718454\n",
      "[45]\tvalid_0's l1: 0.0718356\n",
      "[46]\tvalid_0's l1: 0.0718222\n",
      "[47]\tvalid_0's l1: 0.0718177\n",
      "[48]\tvalid_0's l1: 0.0717932\n",
      "[49]\tvalid_0's l1: 0.0717816\n",
      "[50]\tvalid_0's l1: 0.0717563\n",
      "[51]\tvalid_0's l1: 0.0717517\n",
      "[52]\tvalid_0's l1: 0.0717476\n",
      "[53]\tvalid_0's l1: 0.0717552\n",
      "[54]\tvalid_0's l1: 0.0717516\n",
      "[55]\tvalid_0's l1: 0.0717569\n",
      "[56]\tvalid_0's l1: 0.0717744\n",
      "[57]\tvalid_0's l1: 0.0717858\n",
      "[58]\tvalid_0's l1: 0.0717957\n",
      "[59]\tvalid_0's l1: 0.0717889\n",
      "[60]\tvalid_0's l1: 0.0717795\n",
      "[61]\tvalid_0's l1: 0.07179\n",
      "[62]\tvalid_0's l1: 0.0717776\n",
      "[63]\tvalid_0's l1: 0.071769\n",
      "[64]\tvalid_0's l1: 0.0717786\n",
      "[65]\tvalid_0's l1: 0.0718027\n",
      "[66]\tvalid_0's l1: 0.0717885\n",
      "[67]\tvalid_0's l1: 0.0717498\n",
      "[68]\tvalid_0's l1: 0.071748\n",
      "[69]\tvalid_0's l1: 0.0717405\n",
      "[70]\tvalid_0's l1: 0.0717513\n",
      "[71]\tvalid_0's l1: 0.0717407\n",
      "[72]\tvalid_0's l1: 0.0717317\n",
      "[73]\tvalid_0's l1: 0.0717292\n",
      "[74]\tvalid_0's l1: 0.071709\n",
      "[75]\tvalid_0's l1: 0.0716978\n",
      "[76]\tvalid_0's l1: 0.0717041\n",
      "[77]\tvalid_0's l1: 0.0716828\n",
      "[78]\tvalid_0's l1: 0.0716646\n",
      "[79]\tvalid_0's l1: 0.0716554\n",
      "[80]\tvalid_0's l1: 0.0716574\n",
      "[81]\tvalid_0's l1: 0.0716142\n",
      "[82]\tvalid_0's l1: 0.0716006\n",
      "[83]\tvalid_0's l1: 0.0715925\n",
      "[84]\tvalid_0's l1: 0.071572\n",
      "[85]\tvalid_0's l1: 0.0715716\n",
      "[86]\tvalid_0's l1: 0.0715675\n",
      "[87]\tvalid_0's l1: 0.0715625\n",
      "[88]\tvalid_0's l1: 0.0715596\n",
      "[89]\tvalid_0's l1: 0.071529\n",
      "[90]\tvalid_0's l1: 0.0715214\n",
      "[91]\tvalid_0's l1: 0.0715137\n",
      "[92]\tvalid_0's l1: 0.0715051\n",
      "[93]\tvalid_0's l1: 0.0714961\n",
      "[94]\tvalid_0's l1: 0.0714931\n",
      "[95]\tvalid_0's l1: 0.0715121\n",
      "[96]\tvalid_0's l1: 0.0715029\n",
      "[97]\tvalid_0's l1: 0.0715025\n",
      "[98]\tvalid_0's l1: 0.0715049\n",
      "[99]\tvalid_0's l1: 0.0715135\n",
      "[100]\tvalid_0's l1: 0.0715129\n",
      "[101]\tvalid_0's l1: 0.0715169\n",
      "[102]\tvalid_0's l1: 0.0715223\n",
      "[103]\tvalid_0's l1: 0.0715184\n",
      "[104]\tvalid_0's l1: 0.0715145\n",
      "[105]\tvalid_0's l1: 0.0715266\n",
      "[106]\tvalid_0's l1: 0.0715075\n",
      "[107]\tvalid_0's l1: 0.0715069\n",
      "[108]\tvalid_0's l1: 0.0714912\n",
      "[109]\tvalid_0's l1: 0.0714833\n",
      "[110]\tvalid_0's l1: 0.0714975\n",
      "[111]\tvalid_0's l1: 0.0714932\n",
      "[112]\tvalid_0's l1: 0.0714974\n",
      "[113]\tvalid_0's l1: 0.0714995\n",
      "[114]\tvalid_0's l1: 0.0715126\n",
      "[115]\tvalid_0's l1: 0.0715117\n",
      "[116]\tvalid_0's l1: 0.0715099\n",
      "[117]\tvalid_0's l1: 0.0714974\n",
      "[118]\tvalid_0's l1: 0.0714929\n",
      "[119]\tvalid_0's l1: 0.0714882\n",
      "[120]\tvalid_0's l1: 0.0714851\n",
      "[121]\tvalid_0's l1: 0.0714729\n",
      "[122]\tvalid_0's l1: 0.0714718\n",
      "[123]\tvalid_0's l1: 0.0714596\n",
      "[124]\tvalid_0's l1: 0.0714474\n",
      "[125]\tvalid_0's l1: 0.071448\n",
      "[126]\tvalid_0's l1: 0.071447\n",
      "[127]\tvalid_0's l1: 0.0714282\n",
      "[128]\tvalid_0's l1: 0.0714083\n",
      "[129]\tvalid_0's l1: 0.0714345\n",
      "[130]\tvalid_0's l1: 0.0714389\n",
      "[131]\tvalid_0's l1: 0.0714355\n",
      "[132]\tvalid_0's l1: 0.0714288\n",
      "[133]\tvalid_0's l1: 0.0714231\n",
      "[134]\tvalid_0's l1: 0.0714295\n",
      "[135]\tvalid_0's l1: 0.0714269\n",
      "[136]\tvalid_0's l1: 0.0714213\n",
      "[137]\tvalid_0's l1: 0.0714248\n",
      "[138]\tvalid_0's l1: 0.0714238\n",
      "[139]\tvalid_0's l1: 0.0714267\n",
      "[140]\tvalid_0's l1: 0.0714252\n",
      "[141]\tvalid_0's l1: 0.0714227\n",
      "[142]\tvalid_0's l1: 0.0713991\n",
      "[143]\tvalid_0's l1: 0.0713944\n",
      "[144]\tvalid_0's l1: 0.0713972\n",
      "[145]\tvalid_0's l1: 0.0714061\n",
      "[146]\tvalid_0's l1: 0.0714111\n",
      "[147]\tvalid_0's l1: 0.0714147\n",
      "[148]\tvalid_0's l1: 0.0714153\n",
      "[149]\tvalid_0's l1: 0.071419\n",
      "[150]\tvalid_0's l1: 0.0714328\n",
      "[151]\tvalid_0's l1: 0.0714314\n",
      "[152]\tvalid_0's l1: 0.0714442\n",
      "[153]\tvalid_0's l1: 0.0714291\n",
      "[154]\tvalid_0's l1: 0.0714275\n",
      "[155]\tvalid_0's l1: 0.0714367\n",
      "[156]\tvalid_0's l1: 0.0714571\n",
      "[157]\tvalid_0's l1: 0.0714745\n",
      "[158]\tvalid_0's l1: 0.0714668\n",
      "[159]\tvalid_0's l1: 0.0714876\n",
      "[160]\tvalid_0's l1: 0.0715029\n",
      "[161]\tvalid_0's l1: 0.0715097\n",
      "[162]\tvalid_0's l1: 0.0715114\n",
      "[163]\tvalid_0's l1: 0.0715051\n",
      "[164]\tvalid_0's l1: 0.0714936\n",
      "[165]\tvalid_0's l1: 0.0714998\n",
      "[166]\tvalid_0's l1: 0.0715232\n",
      "[167]\tvalid_0's l1: 0.0715421\n",
      "[168]\tvalid_0's l1: 0.0715584\n",
      "[169]\tvalid_0's l1: 0.0715648\n",
      "[170]\tvalid_0's l1: 0.0715532\n",
      "[171]\tvalid_0's l1: 0.0715508\n",
      "[172]\tvalid_0's l1: 0.0715462\n",
      "[173]\tvalid_0's l1: 0.0715597\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's l1: 0.0713944\n",
      "Feature names: ['airconditioningtypeid', 'bathroomcnt', 'bedroomcnt', 'buildingqualitytypeid', 'calculatedbathnbr', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet15', 'finishedsquarefeet50', 'fips', 'fullbathcnt', 'garagetotalsqft', 'hashottuborspa', 'heatingorsystemtypeid', 'latitude', 'lotsizesquarefeet', 'poolcnt', 'pooltypeid7', 'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt', 'unitcnt', 'yearbuilt', 'numberofstories', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'landtaxvaluedollarcnt', 'taxamount', 'taxdelinquencyyear', 'censustractandblock', 'N-LivingAreaProp', 'N-LivingAreaProp2', 'N-ExtraSpace', 'N-ExtraSpace-2', 'N-TotalRooms', 'N-AvRoomSize', 'N-ExtraRooms', 'N-ValueProp', 'N-latitude-round', 'N-ValueRatio', 'N-TaxScore', 'N-taxdelinquencyyear-2', 'N-zip_count', 'N-city_count', 'N-structuretaxvaluedollarcnt-2', 'N-structuretaxvaluedollarcnt-3', 'N-Avg-structuretaxvaluedollarcnt', 'N-Dev-structuretaxvaluedollarcnt']\n",
      "Calculate feature importances...\n",
      "Feature importances: [22, 43, 53, 33, 25, 2, 248, 206, 23, 12, 2, 8, 89, 22, 37, 260, 198, 67, 40, 56, 167, 184, 1, 177, 277, 27, 6, 326, 9, 292, 158, 273, 305, 24, 211, 293, 182, 255, 234, 113, 30, 120, 217, 131, 350, 179, 11, 236, 171, 109, 58, 142, 134]\n",
      "                             feature  importances\n",
      "22                    regionidcounty            1\n",
      "5           finishedfloor1squarefeet            2\n",
      "10                              fips            2\n",
      "26                           unitcnt            6\n",
      "11                       fullbathcnt            8\n",
      "28                   numberofstories            9\n",
      "46            N-taxdelinquencyyear-2           11\n",
      "9               finishedsquarefeet50           12\n",
      "13                    hashottuborspa           22\n",
      "0              airconditioningtypeid           22\n",
      "8               finishedsquarefeet15           23\n",
      "33                taxdelinquencyyear           24\n",
      "4                  calculatedbathnbr           25\n",
      "25                           roomcnt           27\n",
      "40                      N-AvRoomSize           30\n",
      "3              buildingqualitytypeid           33\n",
      "14             heatingorsystemtypeid           37\n",
      "18                       pooltypeid7           40\n",
      "1                        bathroomcnt           43\n",
      "2                         bedroomcnt           53\n",
      "19             propertylandusetypeid           56\n",
      "50    N-structuretaxvaluedollarcnt-3           58\n",
      "17                           poolcnt           67\n",
      "12                   garagetotalsqft           89\n",
      "49    N-structuretaxvaluedollarcnt-2          109\n",
      "39                      N-TotalRooms          113\n",
      "41                      N-ExtraRooms          120\n",
      "43                  N-latitude-round          131\n",
      "52  N-Dev-structuretaxvaluedollarcnt          134\n",
      "51  N-Avg-structuretaxvaluedollarcnt          142\n",
      "30                 taxvaluedollarcnt          158\n",
      "20            rawcensustractandblock          167\n",
      "48                      N-city_count          171\n",
      "23              regionidneighborhood          177\n",
      "45                        N-TaxScore          179\n",
      "36                 N-LivingAreaProp2          182\n",
      "21                      regionidcity          184\n",
      "16                 lotsizesquarefeet          198\n",
      "7               finishedsquarefeet12          206\n",
      "34               censustractandblock          211\n",
      "42                       N-ValueProp          217\n",
      "38                    N-ExtraSpace-2          234\n",
      "47                       N-zip_count          236\n",
      "6       calculatedfinishedsquarefeet          248\n",
      "37                      N-ExtraSpace          255\n",
      "15                          latitude          260\n",
      "31             landtaxvaluedollarcnt          273\n",
      "24                       regionidzip          277\n",
      "29        structuretaxvaluedollarcnt          292\n",
      "35                  N-LivingAreaProp          293\n",
      "32                         taxamount          305\n",
      "27                         yearbuilt          326\n",
      "44                      N-ValueRatio          350\n"
     ]
    }
   ],
   "source": [
    "split = 90000\n",
    "train_label = y_train[:split]\n",
    "train_data = x_train[:split]\n",
    "outlier_bracket = (train_label<=0.4)&(train_label>=-0.4)\n",
    "train_data = train_data[outlier_bracket]\n",
    "train_label = train_label[outlier_bracket]\n",
    "\n",
    "d_train = lgb.Dataset(train_data, label=train_label)\n",
    "d_valid = lgb.Dataset(x_train[split:], label=y_train[split:])\n",
    "\n",
    "#params = {}\n",
    "#params['learning_rate'] = 0.02\n",
    "#params['boosting_type'] = 'gbdt'\n",
    "#params['objective'] = 'regression'\n",
    "#params['metric'] = 'mae'\n",
    "#params['sub_feature'] = 0.5\n",
    "#params['num_leaves'] = 96\n",
    "#params['min_data'] = 500\n",
    "#params['min_hessian'] = 10\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'mae'},\n",
    "    'num_leaves': 128,\n",
    "    'min_sum_hessian_in_leaf':20,\n",
    "    'min_hessian':10,\n",
    "    'min_data':500,\n",
    "    'max_depth': 12,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "watchlist = [d_train, d_valid]\n",
    "gbm = lgb.train(params, d_train, num_boost_round=2000, valid_sets=d_valid, early_stopping_rounds=30)\n",
    "\n",
    "print('Feature names:', gbm.feature_name())\n",
    "\n",
    "print('Calculate feature importances...')\n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importance()))\n",
    "\n",
    "df = pd.DataFrame({'feature':gbm.feature_name(), 'importances': gbm.feature_importance()})\n",
    "print(df.sort_values('importances'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare for the prediction ...\n",
      "Start prediction ...\n",
      "Start write result ...\n"
     ]
    }
   ],
   "source": [
    "#del d_train, d_valid; gc.collect()\n",
    "#del x_train, x_valid; gc.collect()\n",
    "\n",
    "print(\"Prepare for the prediction ...\")\n",
    "sample = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\sample_submission.csv')\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(properties, on='parcelid', how='left')\n",
    "df_test = prepare_additional_feature(df_test)\n",
    "#del sample, prop; gc.collect()\n",
    "x_test = df_test[train_columns]\n",
    "del df_test; gc.collect()\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "x_test = x_test.values.astype(np.float32, copy=False)\n",
    "\n",
    "print(\"Start prediction ...\")\n",
    "# num_threads > 1 will predict very slow in kernal\n",
    "gbm.reset_parameter({\"num_threads\":1})\n",
    "p_test = gbm.predict(x_test)\n",
    "\n",
    "del x_test; gc.collect()\n",
    "\n",
    "print(\"Start write result ...\")\n",
    "sub = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test\n",
    "\n",
    "sub.to_csv('lgb_starter.csv.gz', index=False, float_format='%.4f', compression = 'gzip')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "print('Loading data ...')\n",
    "\n",
    "train = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\train_2016.csv')\n",
    "prop = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\properties_2016.csv')\n",
    "\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        prop[c] = prop[c].astype(np.float32)\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "del df_train; gc.collect()\n",
    "\n",
    "split = 90000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "x_valid = x_valid.values.astype(np.float32, copy=False)\n",
    "\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "d_valid = lgb.Dataset(x_valid, label=y_valid)\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = 0.002\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'mae'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 60\n",
    "params['min_data'] = 500\n",
    "params['min_hessian'] = 1\n",
    "\n",
    "watchlist = [d_valid]\n",
    "clf = lgb.train(params, d_train, 500, watchlist)\n",
    "\n",
    "del d_train, d_valid; gc.collect()\n",
    "del x_train, x_valid; gc.collect()\n",
    "\n",
    "print(\"Prepare for the prediction ...\")\n",
    "sample = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\sample_submission.csv')\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "del sample, prop; gc.collect()\n",
    "x_test = df_test[train_columns]\n",
    "del df_test; gc.collect()\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "x_test = x_test.values.astype(np.float32, copy=False)\n",
    "\n",
    "print(\"Start prediction ...\")\n",
    "# num_threads > 1 will predict very slow in kernal\n",
    "clf.reset_parameter({\"num_threads\":1})\n",
    "p_test = clf.predict(x_test)\n",
    "\n",
    "del x_test; gc.collect()\n",
    "\n",
    "print(\"Start write result ...\")\n",
    "sub = pd.read_csv('C:\\\\Kaggle\\\\Zillow\\\\input\\\\sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test\n",
    "\n",
    "sub.to_csv('lgb_starter.csv.gz', index=False, float_format='%.4f', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = 80000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "y_train[y_train>0]=1\n",
    "y_train[y_train<=0]=0\n",
    "y_valid[y_valid>0]=1\n",
    "y_valid[y_valid<=0]=0\n",
    "\n",
    "print('Building DMatrix...')\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "del x_train, x_valid; gc.collect()\n",
    "\n",
    "print('Training ...')\n",
    "\n",
    "params = {}\n",
    "params['eta'] = 0.02\n",
    "params['objective'] = 'reg:linear'\n",
    "params['eval_metric'] = ['error','logloss']\n",
    "params['max_depth'] = 8\n",
    "params['silent'] = 1\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "\n",
    "del d_train, d_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Building test set ...')\n",
    "\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "del prop; gc.collect()\n",
    "\n",
    "x_test = df_test[train_columns]\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "\n",
    "del df_test, sample; gc.collect()\n",
    "\n",
    "d_test = xgb.DMatrix(x_test)\n",
    "\n",
    "del x_test; gc.collect()\n",
    "\n",
    "print('Predicting on test ...')\n",
    "\n",
    "p_test = clf.predict(d_test)\n",
    "\n",
    "del d_test; gc.collect()\n",
    "\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test\n",
    "\n",
    "print('Writing csv ...')\n",
    "sub.to_csv('xgb_starter.csv', index=False, float_format='%.4f') # Thanks to @inversion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
